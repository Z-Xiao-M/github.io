<!DOCTYPE html>
<html data-color-mode="light" data-dark-theme="dark" data-light-theme="light" lang="zh-CN">
<head>
    <meta content="text/html; charset=utf-8" http-equiv="content-type" />
    <meta name="viewport" content="width=device-width,initial-scale=1.0">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <link href='https://mirrors.sustech.edu.cn/cdnjs/ajax/libs/Primer/21.0.7/primer.css' rel='stylesheet' />
    <script src='https://blog.meekdai.com/Gmeek/plugins/GmeekVercount.js'></script><script src='https://blog.meekdai.com/Gmeek/plugins/GmeekTOC.js'></script><style>body[data-ui-pending] #content {opacity:0;transition:opacity 0.3s ease;}</style><script>document.documentElement.setAttribute('data-ui-pending','true');</script><link rel='stylesheet' href='https://code.buxiantang.top/assets/GmeekBaseTheme.css'><script src='https://code.buxiantang.top/assets/GmeekCustomizeCss.js' defer></script>
    <link rel="icon" href="https://z-xiao-m.github.io/github.io/avatar.svg"><script>
        let theme = localStorage.getItem("meek_theme") || "light";
        document.documentElement.setAttribute("data-color-mode", theme);
    </script>
<meta name="description" content="#  ONNX 简单介绍
ONNX（Open Neural Network Exchange）由微软与Facebook于2017年联合推出，推出后迅速得到了各大厂商和框架的支持。">
<meta property="og:title" content="在PostgreSQL中运行onnx模型 —— pg_onnx">
<meta property="og:description" content="#  ONNX 简单介绍
ONNX（Open Neural Network Exchange）由微软与Facebook于2017年联合推出，推出后迅速得到了各大厂商和框架的支持。">
<meta property="og:type" content="article">
<meta property="og:url" content="https://Z-Xiao-M.github.io/github.io/post/zai-PostgreSQL-zhong-yun-xing-onnx-mo-xing-%20%E2%80%94%E2%80%94%20pg_onnx.html">
<meta property="og:image" content="https://z-xiao-m.github.io/github.io/avatar.svg">
<title>在PostgreSQL中运行onnx模型 —— pg_onnx</title>



</head>
<style>
body{box-sizing: border-box;min-width: 200px;max-width: 900px;margin: 20px auto;padding: 45px;font-size: 16px;font-family: sans-serif;line-height: 1.25;}
#header{display:flex;padding-bottom:8px;border-bottom: 1px solid var(--borderColor-muted, var(--color-border-muted));margin-bottom: 16px;}
#footer {margin-top:64px; text-align: center;font-size: small;}

</style>

<style>
.postTitle{margin: auto 0;font-size:40px;font-weight:bold;}
.title-right{display:flex;margin:auto 0 0 auto;}
.title-right .circle{padding: 14px 16px;margin-right:8px;}
#postBody{border-bottom: 1px solid var(--color-border-default);padding-bottom:36px;}
#postBody hr{height:2px;}
#cmButton{height:48px;margin-top:48px;}
#comments{margin-top:64px;}
.g-emoji{font-size:24px;}
@media (max-width: 600px) {
    body {padding: 8px;}
    .postTitle{font-size:24px;}
}

</style>
<style>#postBody{font-size:20px}</style>



<body>
    <div id="header">
<h1 class="postTitle">在PostgreSQL中运行onnx模型 —— pg_onnx</h1>
<div class="title-right">
    <a href="https://Z-Xiao-M.github.io/github.io" id="buttonHome" class="btn btn-invisible circle" title="首页">
        <svg class="octicon" width="16" height="16">
            <path id="pathHome" fill-rule="evenodd"></path>
        </svg>
    </a>
    
    <a href="https://github.com/Z-Xiao-M/github.io/issues/46" target="_blank" class="btn btn-invisible circle" title="Issue">
        <svg class="octicon" width="16" height="16">
            <path id="pathIssue" fill-rule="evenodd"></path>
        </svg>
    </a>
    

    <a class="btn btn-invisible circle" onclick="modeSwitch();" title="切换主题">
        <svg class="octicon" width="16" height="16" >
            <path id="themeSwitch" fill-rule="evenodd"></path>
        </svg>
    </a>

</div>
</div>
    <div id="content">
<div class="markdown-body" id="postBody"><h1>ONNX 简单介绍</h1>
<p>ONNX（Open Neural Network Exchange）由微软与Facebook于2017年联合推出，推出后迅速得到了各大厂商和框架的支持。<br>
<a target="_blank" rel="noopener noreferrer" href="https://github.com/user-attachments/assets/ee4e1b12-6c23-4b62-bc17-7a86832a52f3"><img width="1254" height="806" alt="Image" src="https://github.com/user-attachments/assets/ee4e1b12-6c23-4b62-bc17-7a86832a52f3" style="max-width: 100%; height: auto; max-height: 806px;"></a><br>
其核心机制在于定义了一套与平台无关的统一算子和计算图规范：无论使用何种训练框架（如: PyTorch、TensorFlow、Scikit-learn、MXNet）构建模型，只需将其转换为ONNX格式，就能在任何支持ONNX Runtime的环境中运行——从云端服务器到边缘设备，从移动端到Web浏览器。这种标准化不仅实现了真正的"一次训练，随处部署"，更构建起一个开放的跨生态协作网络。让开发者不必疲于应对环境适配，得以挣脱框架锁定的束缚，从而专注算法创新。</p>
<p>想了解更多详细信息请关注<a href="https://onnx.ai/" rel="nofollow">ONNX | Home</a>或<a href="https://github.com/onnx/onnx">GitHub</a></p>
<h1>ONNX Runtime 简单介绍</h1>
<p>ONNX Runtime（ORT）是微软推出的跨平台、高性能、专为ONNX 模型打造的AI <strong>推理引擎</strong>，其核心价值在于为 ONNX 格式模型提供统一、高效的运行环境：它支持跨平台部署，兼容 Windows、Linux、macOS、Android、iOS 等系统及 x86、ARM 等芯片架构，能适配 CPU、GPU、NPU 等各类硬件；同时提供 Python、C++、C#、JavaScript、Java 等多种API开发接口。</p>
<p><a target="_blank" rel="noopener noreferrer" href="https://github.com/user-attachments/assets/d98c729c-42e5-4965-a751-b80441132850"><img width="1505" height="595" alt="Image" src="https://github.com/user-attachments/assets/d98c729c-42e5-4965-a751-b80441132850" style="max-width: 100%; height: auto; max-height: 595px;"></a></p>
<p>想了解更多详细信息请关注<a href="https://onnxruntime.ai/" rel="nofollow">ONNX Runtime | Home</a>或<a href="https://github.com/microsoft/onnxruntime">GitHub</a></p>
<h1>现实中的痛点</h1>
<p><strong>ML模型开发者的痛点</strong></p>
<ul>
<li>主要使用Python生态系统（Transformers, scikit-learn, pandas）</li>
<li>训练数据多为CSV文件格式</li>
<li>擅长训练但不擅长将模型部署为API服务</li>
</ul>
<p><strong>后端开发者的痛点</strong></p>
<ul>
<li>熟悉调用外部API和DBMS，习惯结构化响应（如JSON）</li>
<li>不了解如何执行ML模型</li>
<li>担心ML模型作为资源消耗大的黑盒带来的潜在风险</li>
<li>缺乏GPU资源管理经验</li>
</ul>
<p><strong>引申出三个需求</strong></p>
<ul>
<li>想要用数据库中的数据做推理，该怎么办？</li>
<li>想要把推理结果存入数据库中并用于查询过滤，该怎么办？</li>
<li>想要自动化这一切，该怎么办？</li>
</ul>
<h1>pg_onnx</h1>
<p>pg_onnx 是 PostgreSQL 的扩展插件，核心是通过<strong>集成 ONNX Runtime，让机器学习模型在数据库内直接完成推理</strong>，无需跨系统迁移数据。</p>
<ul>
<li>打通 “数据库存储” 与 “ML 推理” 的链路，解决数据迁移、跨系统协作的效率问题。</li>
<li>适配主流框架导出的 ONNX 模型，支持在 PostgreSQL 内部完成模型加载、会话管理和推理执行。</li>
<li>消除协作壁垒：适配 ML 模型师（Python 生态）和后端开发（DB/API 生态）的使用习惯。</li>
<li>提升推理效率：数据无需导出，减少传输延迟，支持 CUDA GPU 加速。</li>
<li>简化技术架构：无需额外搭建推理服务，直接通过 SQL 函数或触发器调用模型。</li>
<li>提供完整模型管理函数：支持 ONNX 模型的导入、删除、列表查询和详情查看。</li>
<li>支持会话管理：可创建、执行、销毁推理会话，灵活适配不同推理场景。</li>
<li>触发器联动：能通过 PostgreSQL 触发器，在数据插入 / 更新时自动触发推理并存储结果。</li>
</ul>
<p>整体架构如下图所示，来自作者23年pgday的<a href="https://pgday.postgresql.kr/static/pgday-2023pg_onnx.pdf" rel="nofollow">pdf</a>分享</p>
<p><a target="_blank" rel="noopener noreferrer" href="https://github.com/user-attachments/assets/d9408f4d-a9ba-4fdd-b8bb-1fc84b0c52a7"><img width="1145" height="511" alt="Image" src="https://github.com/user-attachments/assets/d9408f4d-a9ba-4fdd-b8bb-1fc84b0c52a7" style="max-width: 100%; height: auto; max-height: 511px;"></a></p>
<p>采用 “PostgreSQL 扩展 + ONNX Runtime+Background Worker” 分离设计</p>
<ul>
<li>pg_onnx作为PostgreSQL 扩展，负责 SQL 入口接收请求（其实就是pg_onnx提供了一系列的函数）</li>
</ul>
<pre lang="sql" class="notranslate"><code class="notranslate">postgres=# create extension pg_onnx;
CREATE EXTENSION
postgres=# select proname from pg_proc where proname like 'pg_onnx%';
          proname          
---------------------------
 pg_onnx_inspect_model_bin
 pg_onnx_list_model
 pg_onnx_import_model
 pg_onnx_drop_model
 pg_onnx_list_session
 pg_onnx_create_session
 pg_onnx_describe_session
 pg_onnx_destroy_session
 pg_onnx_execute_session
</code></pre>
<ul>
<li>onnxruntime-server其实就是封装了ONNX Runtime，作为Background Worker，提供服务。比如说：集中执行推理，会话管理以及CUDA GPU 加速。</li>
</ul>
<pre lang="bash" class="notranslate"><code class="notranslate">postgres=# \! ps -aux|grep postgres:
postgres  160845  0.0  0.0  70648  4568 ?        Ss   22:18   0:00 postgres: logger 
postgres  160846  0.0  0.0 217472 10016 ?        Ss   22:18   0:00 postgres: checkpointer 
postgres  160847  0.0  0.0 217492  6812 ?        Ss   22:18   0:00 postgres: background writer 
postgres  160849  0.0  0.0 217340  9592 ?        Ss   22:18   0:00 postgres: walwriter 
postgres  160850  0.0  0.0 218944  8796 ?        Ss   22:18   0:00 postgres: autovacuum launcher 
postgres  160851  0.0  0.0 218920  7964 ?        Ss   22:18   0:00 postgres: logical replication launcher 
postgres  160853  0.0  0.1 243376 28624 ?        Ss   22:18   0:00 postgres: postgres postgres [local] idle
postgres  160854  0.0  0.0 346744 12924 ?        Ssl  22:18   0:00 postgres: pg_onnx 
</code></pre>
<p>pg_onnx和onnxruntime-server，其实就是标准的CS模型，一个作为客户端，一个作为服务端。二者通过 TCP/IP 通信避免多进程重复加载模型导致的资源枯竭。对于通信方面更具体一点，更具体一点其实是本地回环，否者网络消耗又上去了。另外值得注意的是，在导入模型时，会将传入的模型作为大对象来管理。</p>
<h1>生成线性回归模型</h1>
<p>线性回归是机器学习中最简单的模型，前不久薛晓刚薛老师也写了一篇关于相似的文章<a href="https://mp.weixin.qq.com/s/nBQKPBZyOgRq8eWvtxuj0w" rel="nofollow">Oracle和MySQL数据库中做线性回归</a>，感兴趣的朋友可以再去了解了解，写的比我详细。<strong>回到正文</strong>，这里我没有使用onnx自身定义的算子，去生成线性回归模型，而是使用的<strong>pytorch</strong>。你可以参考官方文档的<a href="https://onnx.ai/onnx/intro/python.html#a-simple-example-a-linear-regression" rel="nofollow">ONNX with Python</a>写法来实现这个线性回归模型。</p>
<pre lang="python" class="notranslate"><code class="notranslate">import numpy as np
import torch
from torch import nn

class UnaryLinearReg(nn.Module):
    def __init__(self):
        super().__init__()
        self.linear = nn.Linear(1, 1)

    def forward(self, x):
        return self.linear(x)

def main():
    # y ≈ 3x + 2 + noise
    np.random.seed(0)
    x = np.random.uniform(0, 10, size=(10000, 1)).astype(np.float32)
    noise = np.random.normal(0, 0.5, size=(10000, 1)).astype(np.float32)
    labels = 3 * x + 2 + noise

    model = UnaryLinearReg()
    loss_fn = nn.MSELoss()
    optimizer = torch.optim.SGD(model.parameters(), lr=0.01)

    epochs = 20
    batch_size = 100
    for epoch in range(epochs):
        for i in range(0, len(x), batch_size):
            batch_x = torch.from_numpy(x[i:i + batch_size])
            batch_y = torch.from_numpy(labels[i:i + batch_size])

            optimizer.zero_grad()
            pred = model(batch_x)
            loss = loss_fn(pred, batch_y)
            loss.backward()
            optimizer.step()

        if epoch % 2 == 0:
            print(f"epoch {epoch:2d} | loss {loss.item():.4f}")

    w, b = model.parameters()
    print(f"w = {w.item():.3f}, b = {b.item():.3f}")

    torch.onnx.export(
        model,
        torch.randn(1, 1), 
        "model.onnx",
        input_names=['x'], 
        output_names=['y'], 
        dynamic_shapes={'x': {0: 'batch'}},
        opset_version=18,
    )

if __name__ == '__main__':
    main()
</code></pre>
<h1>简单测试</h1>
<pre lang="sql" class="notranslate"><code class="notranslate">postgres=# SELECT pg_onnx_import_model(
               'sample_model', --------------- model name
               'v1', ------------------ model version 
               PG_READ_BINARY_FILE('/home/postgres/model.onnx')::bytea, -- model binary data
               '{"cuda": false}'::jsonb, ------ options
               'sample model' ---------------- description
       );
 pg_onnx_import_model 
----------------------
 t
(1 行记录)

postgres=# select * from pg_onnx_list_model();
     name     | version |     option      |         inputs         |        outputs         | description  |          created_at           | lo_oid 
--------------+---------+-----------------+------------------------+------------------------+--------------+-------------------------------+--------
 sample_model | v1      | {"cuda": false} | {"x": "float32[-1,1]"} | {"y": "float32[-1,1]"} | sample model | 2025-11-16 23:08:42.618817+08 |  25144
(1 行记录)

postgres=# SELECT pg_onnx_execute_session(
               'sample_model', -- model name
               'v1', ----- model version
               '{
                 "x": [[1], [2], [3], [4]]
               }' --------------- inputs
       );
                                    pg_onnx_execute_session                                    
-----------------------------------------------------------------------------------------------
 {"y": [[4.985114097595215], [7.989638805389404], [10.994163513183594], [13.998688697814941]]}
(1 行记录)
</code></pre>
<h1>其他注意事项</h1>
<h2>PostgreSQL的编译选项需要附上<code class="notranslate">--enable-nls</code></h2>
<p>否则在编译pg_onnx时，可能会出现下面的编译错误提示，没有花时间仔细研究，到底是为什么</p>
<pre lang="bash" class="notranslate"><code class="notranslate">In file included from /u01/app/halo/product/dbms/16/include/postgresql/server/postgres.h:45,
                 from /home/postgres/code/16/contrib/pg_onnx/pg_onnx/bridge/bgworker_side/../../pg_onnx.hpp:14,
                 from /home/postgres/code/16/contrib/pg_onnx/pg_onnx/bridge/bgworker_side/bgworker_side.hpp:8,
                 from /home/postgres/code/16/contrib/pg_onnx/pg_onnx/bridge/bgworker_side/bgworker.cpp:5:
/usr/include/libintl.h:39:14: error: expected unqualified-id before ‘const’
   39 | extern char *gettext (const char *__msgid)
      |              ^~~~~~~
/usr/include/libintl.h:39:14: error: expected ‘)’ before ‘const’
/u01/app/halo/product/dbms/16/include/postgresql/server/c.h:1190:20: note: to match this ‘(’
 1190 | #define gettext(x) (x)
      |                    ^
/usr/include/libintl.h:44:14: error: expected unqualified-id before ‘const’
   44 | extern char *dgettext (const char *__domainname, const char *__msgid)
      |              ^~~~~~~~
/usr/include/libintl.h:44:14: error: expected ‘)’ before ‘const’
/u01/app/halo/product/dbms/16/include/postgresql/server/c.h:1191:23: note: to match this ‘(’
 1191 | #define dgettext(d,x) (x)
      |                       ^
/usr/include/libintl.h:61:14: error: expected unqualified-id before ‘unsigned’
   61 | extern char *ngettext (const char *__msgid1, const char *__msgid2,
      |              ^~~~~~~~
/usr/include/libintl.h:61:14: error: expected ‘)’ before ‘unsigned’
/u01/app/halo/product/dbms/16/include/postgresql/server/c.h:1192:26: note: to match this ‘(’
 1192 | #define ngettext(s,p,n) ((n) == 1 ? (s) : (p))
      |                          ^
/usr/include/libintl.h:61:14: error: expected ‘)’ before ‘unsigned’
   61 | extern char *ngettext (const char *__msgid1, const char *__msgid2,
      |              ^~~~~~~~
/u01/app/halo/product/dbms/16/include/postgresql/server/c.h:1192:25: note: to match this ‘(’
 1192 | #define ngettext(s,p,n) ((n) == 1 ? (s) : (p))
      |                         ^
/usr/include/libintl.h:67:14: error: expected unqualified-id before ‘unsigned’
   67 | extern char *dngettext (const char *__domainname, const char *__msgid1,
      |              ^~~~~~~~~
</code></pre>
<h2>max supported IR version: 11 和 opset 23</h2>
<pre lang="sql" class="notranslate"><code class="notranslate">test=# SELECT pg_onnx_import_model(
               'simple_model',
               'v2', 
               PG_READ_BINARY_FILE('/home/postgres/model/simple_model.onnx')::bytea,
               '{"cuda": false}'::jsonb, 
               'simple_model'
       );
ERROR:  pg_onnx_inspect_model_bin: /onnxruntime_src/onnxruntime/core/graph/model.cc:181 onnxruntime::Model::Model(onnx::ModelProto&amp;&amp;, const onnxruntime::PathString&amp;, const onnxruntime::IOnnxRuntimeOpSchemaRegistryList*, const onnxruntime::logging::Logger&amp;, const onnxruntime::ModelOptions&amp;) Unsupported model IR version: 12, max supported IR version: 11
test=# SELECT pg_onnx_import_model(
               'simple_model',
               'v2', 
               PG_READ_BINARY_FILE('/home/postgres/model/simple_model.onnx')::bytea,
               '{"cuda": false}'::jsonb, 
               'simple_model'
       );
ERROR:  pg_onnx_inspect_model_bin: /onnxruntime_src/onnxruntime/core/graph/model_load_utils.h:46 void onnxruntime::model_load_utils::ValidateOpsetForDomain(const std::unordered_map&lt;std::__cxx11::basic_string&lt;char&gt;, int&gt;&amp;, const onnxruntime::logging::Logger&amp;, bool, const std::string&amp;, int) ONNX Runtime only *guarantees* support for models stamped with official released onnx opset versions. Opset 24 is under development and support for this is limited. The operator schemas and or other functionality may change before next ONNX release and in this case ONNX Runtime will not guarantee backward compatibility. Current official support for domain ai.onnx is till opset 23.
</code></pre>
<h2>输入张量的形状计算不对</h2>
<p>这里的det的原始输入张量形状为(-1,3,-1,-1)，实际输入的coordinates.json是一个形状为(1, 3, 160, 160)，总元素数量76800，报错如下</p>
<pre lang="sql" class="notranslate"><code class="notranslate">(onnx-env) postgres@zxm-VMware-Virtual-Platform:~$ psql test
psql (16.10)
Type "help" for help.

test=# select * from pg_onnx_list_model() where name = 'det';
 name | version |     option      |            inputs            |                 outputs                 | description |          created_at           | lo_oid 
------+---------+-----------------+------------------------------+-----------------------------------------+-------------+-------------------------------+--------
 det  | v1      | {"cuda": false} | {"x": "float32[-1,3,-1,-1]"} | {"fetch_name_0": "float32[-1,1,-1,-1]"} | det         | 2025-10-22 17:59:12.502754+08 |  33180
(1 row)

test=# SELECT pg_onnx_execute_session(
    'det', 
    'v1', 
    pg_read_file('/home/postgres/OnnxOCR/coordinates.json')::jsonb
);
ERROR:  pg_onnx_internal_execute_session: tried creating tensor with negative value in shape
</code></pre>
<p>原因在于，pg_onnx依赖的子项目<a href="https://github.com/kibae/onnxruntime-server">onnxruntime-server</a>对于多维张量的计算是存在问题的，在计算的过程中会调用input_value::batched_shape这个函数，函数实现如下</p>
<pre lang="c++" class="notranslate"><code class="notranslate">std::vector&lt;int64_t&gt;
onnxruntime_server::onnx::execution::input_value::batched_shape(const std::vector&lt;int64_t&gt; &amp;shape, size_t value_count) {
	// check shape contains -1
	if (std::find(shape.begin(), shape.end(), -1) == shape.end())
		return shape;

	// calculate batch size
	std::vector&lt;int64_t&gt; shape_copy = shape;
	int64_t batch = (int64_t)value_count;
	for (auto &amp;s : shape_copy) {
		if (s != -1)
			batch = (int64_t)std::max((double)1, std::ceil((double)batch / (double)s));
	}

	// replace -1 with batch size
	for (auto &amp;s : shape_copy) {
		if (s == -1) {
			s = batch;
			break;
		}
	}

	return shape_copy;
}
</code></pre>
<p>而输入这是原始张量形状和当前输入张量的元素总数分别是(-1, 3, -1, -1)和76800，导致最终计算结果为(25600, 3, -1, -1)，这和实际输入张量的形状(1, 3, 160, 160)完全是对不上的，所以导致报错。然后我就尝试着修复了一下, <strong>值得注意的是，对于bool类型的张量还是原来的处理逻辑，因为我没有这个测试场景的需求，所以待测试</strong><br>
<a target="_blank" rel="noopener noreferrer" href="https://github.com/user-attachments/assets/7669678e-d792-4e77-9b07-64546b8d1e54"><img width="925" height="767" alt="Image" src="https://github.com/user-attachments/assets/7669678e-d792-4e77-9b07-64546b8d1e54" style="max-width: 100%; height: auto; max-height: 767px;"></a></p></div>
<div style="font-size:small;margin-top:8px;float:right;">❤️ 转载文章请注明出处，谢谢！❤️</div>

<button class="btn btn-block" type="button" onclick="openComments()" id="cmButton">评论</button>
<div class="comments" id="comments"></div>

</div>
    <div id="footer"><div id="footer1">Copyright © <span id="copyrightYear"></span> <a href="https://Z-Xiao-M.github.io/github.io">包里装着个卡比兽</a></div>
<div id="footer2">
    <span id="runday"></span><span>Powered by <a href="https://meekdai.com/Gmeek.html" target="_blank">Gmeek</a></span>
</div>

<script>
var now=new Date();
document.getElementById("copyrightYear").innerHTML=now.getFullYear();

if("08/31/2025"!=""){
    var startSite=new Date("08/31/2025");
    var diff=now.getTime()-startSite.getTime();
    var diffDay=Math.floor(diff/(1000*60*60*24));
    document.getElementById("runday").innerHTML="网站运行"+diffDay+"天"+" • ";
}
</script></div>
</body>
<script>
var IconList={'sun': 'M8 10.5a2.5 2.5 0 100-5 2.5 2.5 0 000 5zM8 12a4 4 0 100-8 4 4 0 000 8zM8 0a.75.75 0 01.75.75v1.5a.75.75 0 01-1.5 0V.75A.75.75 0 018 0zm0 13a.75.75 0 01.75.75v1.5a.75.75 0 01-1.5 0v-1.5A.75.75 0 018 13zM2.343 2.343a.75.75 0 011.061 0l1.06 1.061a.75.75 0 01-1.06 1.06l-1.06-1.06a.75.75 0 010-1.06zm9.193 9.193a.75.75 0 011.06 0l1.061 1.06a.75.75 0 01-1.06 1.061l-1.061-1.06a.75.75 0 010-1.061zM16 8a.75.75 0 01-.75.75h-1.5a.75.75 0 010-1.5h1.5A.75.75 0 0116 8zM3 8a.75.75 0 01-.75.75H.75a.75.75 0 010-1.5h1.5A.75.75 0 013 8zm10.657-5.657a.75.75 0 010 1.061l-1.061 1.06a.75.75 0 11-1.06-1.06l1.06-1.06a.75.75 0 011.06 0zm-9.193 9.193a.75.75 0 010 1.06l-1.06 1.061a.75.75 0 11-1.061-1.06l1.06-1.061a.75.75 0 011.061 0z', 'moon': 'M9.598 1.591a.75.75 0 01.785-.175 7 7 0 11-8.967 8.967.75.75 0 01.961-.96 5.5 5.5 0 007.046-7.046.75.75 0 01.175-.786zm1.616 1.945a7 7 0 01-7.678 7.678 5.5 5.5 0 107.678-7.678z', 'sync': 'M1.705 8.005a.75.75 0 0 1 .834.656 5.5 5.5 0 0 0 9.592 2.97l-1.204-1.204a.25.25 0 0 1 .177-.427h3.646a.25.25 0 0 1 .25.25v3.646a.25.25 0 0 1-.427.177l-1.38-1.38A7.002 7.002 0 0 1 1.05 8.84a.75.75 0 0 1 .656-.834ZM8 2.5a5.487 5.487 0 0 0-4.131 1.869l1.204 1.204A.25.25 0 0 1 4.896 6H1.25A.25.25 0 0 1 1 5.75V2.104a.25.25 0 0 1 .427-.177l1.38 1.38A7.002 7.002 0 0 1 14.95 7.16a.75.75 0 0 1-1.49.178A5.5 5.5 0 0 0 8 2.5Z', 'home': 'M6.906.664a1.749 1.749 0 0 1 2.187 0l5.25 4.2c.415.332.657.835.657 1.367v7.019A1.75 1.75 0 0 1 13.25 15h-3.5a.75.75 0 0 1-.75-.75V9H7v5.25a.75.75 0 0 1-.75.75h-3.5A1.75 1.75 0 0 1 1 13.25V6.23c0-.531.242-1.034.657-1.366l5.25-4.2Zm1.25 1.171a.25.25 0 0 0-.312 0l-5.25 4.2a.25.25 0 0 0-.094.196v7.019c0 .138.112.25.25.25H5.5V8.25a.75.75 0 0 1 .75-.75h3.5a.75.75 0 0 1 .75.75v5.25h2.75a.25.25 0 0 0 .25-.25V6.23a.25.25 0 0 0-.094-.195Z', 'github': 'M8 0c4.42 0 8 3.58 8 8a8.013 8.013 0 0 1-5.45 7.59c-.4.08-.55-.17-.55-.38 0-.27.01-1.13.01-2.2 0-.75-.25-1.23-.54-1.48 1.78-.2 3.65-.88 3.65-3.95 0-.88-.31-1.59-.82-2.15.08-.2.36-1.02-.08-2.12 0 0-.67-.22-2.2.82-.64-.18-1.32-.27-2-.27-.68 0-1.36.09-2 .27-1.53-1.03-2.2-.82-2.2-.82-.44 1.1-.16 1.92-.08 2.12-.51.56-.82 1.28-.82 2.15 0 3.06 1.86 3.75 3.64 3.95-.23.2-.44.55-.51 1.07-.46.21-1.61.55-2.33-.66-.15-.24-.6-.83-1.23-.82-.67.01-.27.38.01.53.34.19.73.9.82 1.13.16.45.68 1.31 2.69.94 0 .67.01 1.3.01 1.49 0 .21-.15.45-.55.38A7.995 7.995 0 0 1 0 8c0-4.42 3.58-8 8-8Z'};
var utterancesLoad=0;

let themeSettings={
    "dark": ["dark","moon","#00f0ff","dark-blue"],
    "light": ["light","sun","#ff5000","github-light"],
    "auto": ["auto","sync","","preferred-color-scheme"]
};
function changeTheme(mode, icon, color, utheme){
    document.documentElement.setAttribute("data-color-mode",mode);
    document.getElementById("themeSwitch").setAttribute("d",value=IconList[icon]);
    document.getElementById("themeSwitch").parentNode.style.color=color;
    if(utterancesLoad==1){utterancesTheme(utheme);}
}
function modeSwitch(){
    let currentMode=document.documentElement.getAttribute('data-color-mode');
    let newMode = currentMode === "light" ? "dark" : currentMode === "dark" ? "auto" : "light";
    localStorage.setItem("meek_theme", newMode);
    if(themeSettings[newMode]){
        changeTheme(...themeSettings[newMode]);
    }
}
function utterancesTheme(theme){
    const message={type:'set-theme',theme: theme};
    const iframe=document.getElementsByClassName('utterances-frame')[0];
    iframe.contentWindow.postMessage(message,'https://utteranc.es');
}
if(themeSettings[theme]){changeTheme(...themeSettings[theme]);}
console.log("\n %c Gmeek last https://github.com/Meekdai/Gmeek \n","padding:5px 0;background:#02d81d;color:#fff");
</script>

<script>
document.getElementById("pathHome").setAttribute("d",IconList["home"]);
document.getElementById("pathIssue").setAttribute("d",IconList["github"]);



function openComments(){
    cm=document.getElementById("comments");
    cmButton=document.getElementById("cmButton");
    cmButton.innerHTML="loading";
    span=document.createElement("span");
    span.setAttribute("class","AnimatedEllipsis");
    cmButton.appendChild(span);

    script=document.createElement("script");
    script.setAttribute("src","https://utteranc.es/client.js");
    script.setAttribute("repo","Z-Xiao-M/github.io");
    script.setAttribute("issue-term","title");
    
    if(localStorage.getItem("meek_theme")=="dark"){script.setAttribute("theme","dark-blue");}
    else if(localStorage.getItem("meek_theme")=="light") {script.setAttribute("theme","github-light");}
    else{script.setAttribute("theme","preferred-color-scheme");}
    
    script.setAttribute("crossorigin","anonymous");
    script.setAttribute("async","");
    cm.appendChild(script);

    int=self.setInterval("iFrameLoading()",200);
}

function iFrameLoading(){
    var utterances=document.getElementsByClassName('utterances');
    if(utterances.length==1){
        if(utterances[0].style.height!=""){
            utterancesLoad=1;
            int=window.clearInterval(int);
            document.getElementById("cmButton").style.display="none";
            console.log("utterances Load OK");
        }
    }
}



</script>


</html>
