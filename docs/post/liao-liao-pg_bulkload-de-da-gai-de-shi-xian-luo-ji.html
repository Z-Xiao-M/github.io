<!DOCTYPE html>
<html data-color-mode="light" data-dark-theme="dark-blue" data-light-theme="dark" lang="zh-CN">
<head>
    <meta content="text/html; charset=utf-8" http-equiv="content-type" />
    <meta name="viewport" content="width=device-width,initial-scale=1.0">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <link href='https://mirrors.sustech.edu.cn/cdnjs/ajax/libs/Primer/21.0.7/primer.css' rel='stylesheet' />
    <script src='https://blog.meekdai.com/Gmeek/plugins/GmeekVercount.js'></script><script src='https://blog.meekdai.com/Gmeek/plugins/GmeekTOC.js'></script>
    <link rel="icon" href="https://z-xiao-m.github.io/github.io/avatar.svg">
<meta name="description" content="> 好好好，好久不见，最近偶然了解到了pg\_bulkload这一插件，然后花了点时间看了看它是如何实现的，又想到好久没有写东西了，咕了太久，有点怪不好意思的，所以决定写点东西，摆脱鸽子🕊的嫌疑。">
<meta property="og:title" content="聊聊pg_bulkload的大概的实现逻辑">
<meta property="og:description" content="> 好好好，好久不见，最近偶然了解到了pg\_bulkload这一插件，然后花了点时间看了看它是如何实现的，又想到好久没有写东西了，咕了太久，有点怪不好意思的，所以决定写点东西，摆脱鸽子🕊的嫌疑。">
<meta property="og:type" content="article">
<meta property="og:url" content="https://Z-Xiao-M.github.io/github.io/post/liao-liao-pg_bulkload-de-da-gai-de-shi-xian-luo-ji.html">
<meta property="og:image" content="https://z-xiao-m.github.io/github.io/avatar.svg">
<title>聊聊pg_bulkload的大概的实现逻辑</title>



</head>
<style>
body{box-sizing: border-box;min-width: 200px;max-width: 900px;margin: 20px auto;padding: 45px;font-size: 16px;font-family: sans-serif;line-height: 1.25;}
#header{display:flex;padding-bottom:8px;border-bottom: 1px solid var(--borderColor-muted, var(--color-border-muted));margin-bottom: 16px;}
#footer {margin-top:64px; text-align: center;font-size: small;}

</style>

<style>
.postTitle{margin: auto 0;font-size:40px;font-weight:bold;}
.title-right{display:flex;margin:auto 0 0 auto;}
.title-right .circle{padding: 14px 16px;margin-right:8px;}
#postBody{border-bottom: 1px solid var(--color-border-default);padding-bottom:36px;}
#postBody hr{height:2px;}
#cmButton{height:48px;margin-top:48px;}
#comments{margin-top:64px;}
.g-emoji{font-size:24px;}
@media (max-width: 600px) {
    body {padding: 8px;}
    .postTitle{font-size:24px;}
}
.copy-feedback {
    display: none;
    position: absolute;
    top: 10px;
    right: 50px;
    color: var(--color-fg-on-emphasis);
    background-color: var(--color-fg-muted);
    border-radius: 3px;
    padding: 5px 8px;
    font-size: 12px;
}
</style>
<style>#postBody{font-size:20px}<style>.postTitle{white-space: normal; word-wrap: break-word; max-width: 100%;}</style>



<body>
    <div id="header">
<h1 class="postTitle">聊聊pg_bulkload的大概的实现逻辑</h1>
<div class="title-right">
    <a href="https://Z-Xiao-M.github.io/github.io" id="buttonHome" class="btn btn-invisible circle" title="首页">
        <svg class="octicon" width="16" height="16">
            <path id="pathHome" fill-rule="evenodd"></path>
        </svg>
    </a>
    
    <a href="https://github.com/Z-Xiao-M/github.io/issues/14" target="_blank" class="btn btn-invisible circle" title="Issue">
        <svg class="octicon" width="16" height="16">
            <path id="pathIssue" fill-rule="evenodd"></path>
        </svg>
    </a>
    

    <a class="btn btn-invisible circle" onclick="modeSwitch();" title="切换主题"style="display:none;">
        <svg class="octicon" width="16" height="16" >
            <path id="themeSwitch" fill-rule="evenodd"></path>
        </svg>
    </a>

</div>
</div>
    <div id="content">
<div class="markdown-body" id="postBody"><blockquote>
<p>好好好，好久不见，最近偶然了解到了pg_bulkload这一插件，然后花了点时间看了看它是如何实现的，又想到好久没有写东西了，咕了太久，有点怪不好意思的，所以决定写点东西，摆脱鸽子🕊的嫌疑。</p>
</blockquote>
<h1>一、pg_bulkload简单介绍</h1>
<p>pg_bulkload 为PostgreSQL提供高速加载数据的插件。相关链接如下：</p>
<p><a href="https://github.com/ossc-db/pg_bulkload">pg_bulkload项目地址</a></p>
<p><a href="https://ossc-db.github.io/pg_bulkload/pg_bulkload.html" rel="nofollow">pg_bulkload详细使用文档</a></p>
<p><a href="https://ossc-db.github.io/pg_bulkload/index.html" rel="nofollow">copy命令与pg_bulkload拓展的性能比较</a></p>
<p>pg_bulkload内部结构图如下，后续章节我会以CSV格式文件，对pg_bulkload进行分析，源码分析从第四节开始，对前面比较熟悉的同学，可以直接调转至第四节。</p>
<p><a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/f81fbaeef9a870e139d28e80af6c7ebdfdd2db3820a6df145df70d62fff88d32/68747470733a2f2f6f73732d656d637370726f642d7075626c69632e6d6f64622e70726f2f696d6167652f656469746f722f32303234303230342d36613531616130382d383032352d343032322d613634322d3965383163376135346238332e706e67"><img src="https://camo.githubusercontent.com/f81fbaeef9a870e139d28e80af6c7ebdfdd2db3820a6df145df70d62fff88d32/68747470733a2f2f6f73732d656d637370726f642d7075626c69632e6d6f64622e70726f2f696d6167652f656469746f722f32303234303230342d36613531616130382d383032352d343032322d613634322d3965383163376135346238332e706e67" alt="" data-canonical-src="https://oss-emcsprod-public.modb.pro/image/editor/20240204-6a51aa08-8025-4022-a642-9e81c7a54b83.png" style="max-width: 100%;"></a></p>
<h1>二、拓展插件安装</h1>
<p>我此次采用的是源码安装，PostgreSQL版本14.10，你可以点击上述的pg_bulkload项目地址，下载源码文件，或者使用git clone命令，和我一同操作进行编译安装。 </p>
<pre class="notranslate"><code class="notranslate"># 拉取pg_bulkload源代码
git clone https://github.com/ossc-db/pg_bulkload.git  
# 进入源码目录
cd pg_bulkload/
# 如果此时你的源码下载路径不是位于PostgreSQL源码的contrib目录下可以使用以下命令进行编译安装
make USE_PGXS=1
make install 
</code></pre>
<p>如果此时你的源码下载路径刚好是位于PostgreSQL的contrib目录下 此时使用make去编译 会存在一个编译的问题 编译不成功 大致报错如下（仅当前的版本的pg_bulkload）</p>
<pre class="notranslate"><code class="notranslate">make[1]: --pkglibdir: Command not found
gcc -Wall -Wmissing-prototypes -Wpointer-arith -Wdeclaration-after-statement -Werror=vla -Wendif-labels -Wmissing-format-attribute -Wimplicit-fallthrough=3 -Wcast-function-type -Wformat-security -fno-strict-aliasing -fwrapv -fexcess-precision=standard -Wno-format-truncation -Wno-stringop-truncation -g -O0 pg_bulkload.o recovery.o pgut/pgut.o pgut/pgut-fe.o pgut/pgut-list.o  -L../../../src/port -L../../../src/common   -Wl,--as-needed -Wl,-rpath,'/var/lib/pgsql/postgresql_14/lib',--enable-new-dtags -Wl,--build-id  -L../../../src/interfaces/libpq -lpq -L -lpgcommon -lpgport -lz -lreadline -lpthread -lrt -ldl -lm -o pg_bulkload
pgut/pgut.o: In function `pgut_init':
/var/lib/pgsql/14code/postgres/contrib/pg_bulkload/bin/pgut/pgut.c:79: undefined reference to `set_pglocale_pgservice'
pgut/pgut.o: In function `prompt_for_password':
/var/lib/pgsql/14code/postgres/contrib/pg_bulkload/bin/pgut/pgut.c:395: undefined reference to `simple_prompt'
pgut/pgut-list.o: In function `new_list':
/var/lib/pgsql/14code/postgres/contrib/pg_bulkload/bin/pgut/pgut-list.c:114: undefined reference to `palloc'
pgut/pgut-list.o: In function `enlarge_list':
/var/lib/pgsql/14code/postgres/contrib/pg_bulkload/bin/pgut/pgut-list.c:174: undefined reference to `repalloc'
pgut/pgut-list.o: In function `list_free_private':
/var/lib/pgsql/14code/postgres/contrib/pg_bulkload/bin/pgut/pgut-list.c:1565: undefined reference to `pfree'
/var/lib/pgsql/14code/postgres/contrib/pg_bulkload/bin/pgut/pgut-list.c:1568: undefined reference to `pfree'
/var/lib/pgsql/14code/postgres/contrib/pg_bulkload/bin/pgut/pgut-list.c:1569: undefined reference to `pfree'
collect2: error: ld returned 1 exit status
make[1]: *** [../../../src/makefiles/pgxs.mk:475: pg_bulkload] Error 1
make[1]: Leaving directory '/var/lib/pgsql/14code/postgres/contrib/pg_bulkload/bin'
make: *** [Makefile:27: all] Error 2
</code></pre>
<p>此时需要修改pg_bulkload下bin目录中的Makefile</p>
<pre class="notranslate"><code class="notranslate">cd pg_bulkload/
cd bin/
vim Makefile 
# 你可以选择注释掉 PG_LIBS += -L$(shell $(PG_CONFIG) --pkglibdir)  或者是将
# ifdef USE_PGXS
# PG_CONFIG = pg_config
# PGXS := $(shell $(PG_CONFIG) --pgxs)
# 此处的PG_CONFIG = pg_config 放到ifdef前 我更倾向于第二种做法  
# 修改完毕 进行编译
make &amp;&amp; make install 
</code></pre>
<p>我的Makefile修改如图所示</p>
<p><a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/02ac6dcdb3494629a41940688575c05bc63db2b630d05022022cb9c2d852233d/68747470733a2f2f6f73732d656d637370726f642d7075626c69632e6d6f64622e70726f2f696d6167652f656469746f722f32303234303230342d39353132396363372d626134342d346636382d393363622d3165346462626563643562312e706e67"><img src="https://camo.githubusercontent.com/02ac6dcdb3494629a41940688575c05bc63db2b630d05022022cb9c2d852233d/68747470733a2f2f6f73732d656d637370726f642d7075626c69632e6d6f64622e70726f2f696d6167652f656469746f722f32303234303230342d39353132396363372d626134342d346636382d393363622d3165346462626563643562312e706e67" alt="" data-canonical-src="https://oss-emcsprod-public.modb.pro/image/editor/20240204-95129cc7-ba44-4f68-93cb-1e4dbbecd5b1.png" style="max-width: 100%;"></a></p>
<p>编译已通过、接下来进行插件安装，使用<code class="notranslate">create extension pg_bulkload;</code>即可</p>
<pre class="notranslate"><code class="notranslate">[postgres@halo-centos-8-release ~]$ psql
psql (14.10)
Type "help" for help.

postgres=# create extension pg_bulkload;
CREATE EXTENSION
postgres=# \dx
                                     List of installed extensions
    Name     | Version |   Schema   |                           Description                           
-------------+---------+------------+-----------------------------------------------------------------
 pg_bulkload | 3.1.21  | public     | pg_bulkload is a high speed data loading utility for PostgreSQL
 plpgsql     | 1.0     | pg_catalog | PL/pgSQL procedural language
(2 rows)

postgres=# 
</code></pre>
<h1>三、简单使用</h1>
<p>其实有很多大佬已经给出了非常详细的使用方式了，所以此处我就简单巴拉巴拉两嘴。</p>
<pre class="notranslate"><code class="notranslate">-- 使用halo用户在postgres数据库下 创建表foo
create table foo(a int, b varchar);
-- 退出数据库
\q
</code></pre>
<p>生成点数据</p>
<pre class="notranslate"><code class="notranslate">seq 100000| awk '{print $0",foo"}' &gt; foo.csv
</code></pre>
<p>接下来使用pg_bulkload 导入数据，有两种方式，一种是不使用ctl文件</p>
<pre class="notranslate"><code class="notranslate"># 此处输入文件为foo.csv 输出对应到foo表 指定生成日志为test_foo.log 处理以csv的处理方式处理输入文件 分隔符为"," 端口号 数据库名 操作用户 依据自己的实际情况进行更改 
[postgres@halo-centos-8-release ~]$ pg_bulkload -i ./foo.csv -O foo -l test_foo.log -p 5434 -o "TYPE=csv" -o "DELIMITER=," -d postgres -U halo
NOTICE: BULK LOAD START
NOTICE: BULK LOAD END
        0 Rows skipped.
        100000 Rows successfully loaded.
        0 Rows not loaded due to parse errors.
        0 Rows not loaded due to duplicate errors.
        0 Rows replaced with new rows.
# 查看日志
[postgres@halo-centos-8-release ~]$ cat test_foo.log

pg_bulkload 3.1.21 on 2024-02-05 10:55:03.159387+08

INPUT = /var/lib/pgsql/foo.csv
PARSE_BADFILE = /var/lib/pgsql/14/pg_bulkload/20240205105503_postgres_public_foo.prs.csv
LOGFILE = /var/lib/pgsql/test_foo.log
LIMIT = INFINITE
PARSE_ERRORS = 0
CHECK_CONSTRAINTS = NO
TYPE = CSV
SKIP = 0
DELIMITER = ,
QUOTE = "\""
ESCAPE = "\""
NULL = 
OUTPUT = public.foo
MULTI_PROCESS = NO
VERBOSE = NO
WRITER = DIRECT
DUPLICATE_BADFILE = /var/lib/pgsql/14/pg_bulkload/20240205105503_postgres_public_foo.dup.csv
DUPLICATE_ERRORS = 0
ON_DUPLICATE_KEEP = NEW
TRUNCATE = NO


  0 Rows skipped.
  100000 Rows successfully loaded.
  0 Rows not loaded due to parse errors.
  0 Rows not loaded due to duplicate errors.
  0 Rows replaced with new rows.

Run began on 2024-02-05 10:55:03.159387+08
Run ended on 2024-02-05 10:55:03.218338+08

CPU 0.00s/0.05u sec elapsed 0.06 sec
</code></pre>
<p><strong>第二种是编写ctl文件</strong> 将部分需要传入的参数写入ctl文件中</p>
<pre class="notranslate"><code class="notranslate">[postgres@halo-centos-8-release ~]$ vim sample_csv.ctl
[postgres@halo-centos-8-release ~]$ cat sample_csv.ctl
#
# sample_csv.ctl -- Control file to load CSV input data
#
#    Copyright (c) 2007-2024, NIPPON TELEGRAPH AND TELEPHONE CORPORATION
#
OUTPUT = foo                   # [&lt;schema_name&gt;.]table_name
INPUT = /var/lib/pgsql/foo.csv  # Input data location (absolute path)
TYPE = CSV                            # Input file type
QUOTE = "\""                          # Quoting character
ESCAPE = \                            # Escape character for Quoting
DELIMITER = ","                       # Delimiter

[postgres@halo-centos-8-release ~]$ pg_bulkload ./sample_csv.ctl -d postgres -U halo
NOTICE: BULK LOAD START
NOTICE: BULK LOAD END
        0 Rows skipped.
        100000 Rows successfully loaded.
        0 Rows not loaded due to parse errors.
        0 Rows not loaded due to duplicate errors.
        0 Rows replaced with new rows.
[postgres@halo-centos-8-release ~]$ 
</code></pre>
<p>当然你也可以将ctl文件写的更加丰富详细 比如说<strong>是否在导数据前 执行truncate  是否需要跳过多少行数据  具体写入方式是什么</strong>之类的 具体可以参考<a href="https://ossc-db.github.io/pg_bulkload/pg_bulkload.html" rel="nofollow">pg_bulkload详细使用文档</a></p>
<pre class="notranslate"><code class="notranslate">[postgres@halo-centos-8-release ~]$ vim sample_csv.ctl 
[postgres@halo-centos-8-release ~]$ cat sample_csv.ctl
OUTPUT = foo                   
INPUT = /var/lib/pgsql/foo.csv 
LOGFILE = /var/lib/pgsql/test_table_foo.log
LIMIT = INFINITE
PARSE_ERRORS = 0
CHECK_CONSTRAINTS = NO
TYPE = CSV
SKIP = 0
DELIMITER = ","
QUOTE = "\""
ESCAPE = "\""
MULTI_PROCESS = NO
WRITER = DIRECT
DUPLICATE_ERRORS = 0
ON_DUPLICATE_KEEP = NEW
TRUNCATE = YES
[postgres@halo-centos-8-release ~]$ pg_bulkload ./sample_csv.ctl -d postgres -U halo
NOTICE: BULK LOAD START
NOTICE: BULK LOAD END
        0 Rows skipped.
        100000 Rows successfully loaded.
        0 Rows not loaded due to parse errors.
        0 Rows not loaded due to duplicate errors.
        0 Rows replaced with new rows.
[postgres@halo-centos-8-release ~]$ cat test_table_foo.log

pg_bulkload 3.1.21 on 2024-02-05 11:58:33.765146+08

INPUT = /var/lib/pgsql/foo.csv
PARSE_BADFILE = /var/lib/pgsql/14/pg_bulkload/20240205115833_postgres_public_foo.prs.csv
LOGFILE = /var/lib/pgsql/test_table_foo.log
LIMIT = INFINITE
PARSE_ERRORS = 0
CHECK_CONSTRAINTS = NO
TYPE = CSV
SKIP = 0
DELIMITER = ,
QUOTE = "\""
ESCAPE = "\""
NULL = 
OUTPUT = public.foo
MULTI_PROCESS = NO
VERBOSE = NO
WRITER = DIRECT
DUPLICATE_BADFILE = /var/lib/pgsql/14/pg_bulkload/20240205115833_postgres_public_foo.dup.csv
DUPLICATE_ERRORS = 0
ON_DUPLICATE_KEEP = NEW
TRUNCATE = YES


  0 Rows skipped.
  100000 Rows successfully loaded.
  0 Rows not loaded due to parse errors.
  0 Rows not loaded due to duplicate errors.
  0 Rows replaced with new rows.

Run began on 2024-02-05 11:58:33.765146+08
Run ended on 2024-02-05 11:58:33.827364+08

CPU 0.01s/0.05u sec elapsed 0.06 sec
</code></pre>
<h1>四、简单分析pg_bulkload程序</h1>
<p>接下来让我们来看看pg_bulkload到底是如何实现的？因此我们先来瞅瞅main函数（精简版本）</p>
<pre class="notranslate"><code class="notranslate">/* main 函数精简之后大概就如下所示 大概五个部分 */
int main(int argc, char *argv[])
{
　　　　/* ...省略部分代码... */
	pgut_init(argc, argv);
　　　　/* ...省略部分代码... */
	i = pgut_getopt(argc, argv, options);
	if (recovery)
	{
　　　　　　　　/* ...省略部分代码... */
		return LoaderRecoveryMain();
	}
	else
	{
　　　　　　　　/* ...省略部分代码... */
		if (control_file[0])
			bulkload_options = list_concat(
				ParseControlFile(control_file), bulkload_options);
　　　　　　　　/* ...省略部分代码... */
		return LoaderLoadMain(bulkload_options);
	}
}
</code></pre>
<h2>4.1、pgut_init</h2>
<p>初始化函数做一些相关的初始化的动作，注意些处理函数，此处不展开。</p>
<h2>4.2、pgut_getopt</h2>
<p>解析传入的命令行相关选项，此函数精简一下 如下所示</p>
<pre class="notranslate"><code class="notranslate">int pgut_getopt(int argc, char **argv, pgut_option options[])
{
	/* Help message and version are handled at first. */
　　　　/* ...省略部分代码... */

	/* Merge default and user options. */
	longopts = option_merge(default_options, options);
	optstring = longopts_to_optstring(longopts);

	/* Assign named options */
	while ((c = getopt_long(argc, argv, optstring, longopts, &amp;optindex)) != -1)
	{
		opt = option_find(c, default_options, options);
		pgut_setopt(opt, optarg, SOURCE_CMDLINE);
	}
　　　　/* ...省略部分代码... */
}
</code></pre>
<p>而此处的支持处理的default_options和options分别是</p>
<pre class="notranslate"><code class="notranslate">static pgut_option default_options[] =
{
  { 'b', 'e', "echo"      , &amp;pgut_echo },
  { 'f', 'E', "elevel"    , set_elevel },
  { 's', 'd', "dbname"    , &amp;dbname },
  { 's', 'h', "host"      , &amp;host },
  { 's', 'p', "port"      , &amp;port },
  { 's', 'U', "username"    , &amp;username },
  { 'Y', 'w', "no-password" , &amp;prompt_password },
  { 'y', 'W', "password"    , &amp;prompt_password },
  { 0 }
};

static pgut_option options[] =
{
  /* Dataload options */
  { 's', 'i', "infile"      , &amp;infile },
  { 's', 'i', "input"       , &amp;input },
  { 's', 'O', "output"      , &amp;output },
  { 's', 'l', "logfile"     , &amp;logfile },
  { 's', 'P', "parse-badfile"   , &amp;parse_badfile },
  { 's', 'u', "duplicate-badfile" , &amp;duplicate_badfile },
  { 'f', 'o', "option"      , parse_option },
  /* Recovery options */
  { 's', 'D', "pgdata"      , &amp;DataDir },
  { 'b', 'r', "recovery"      , &amp;recovery },
  { 0 }
};
</code></pre>
<p>当经过option_merge和longopts_to_optstring 此时能够支持处理的选项就变成了<code class="notranslate">eE:d:h:p:U:wWi:i:O:l:P:u:o:D:r</code></p>
<p>然后再配合getopt_long、option_find和pgut_setopt将传入的相关信息保存到程序中，如<code class="notranslate">pg_bulkload -i ./foo.csv -O foo -l test_foo.log -p 5434 -o "TYPE=csv" -o "DELIMITER=," -d postgres -U halo</code>  中的-U halo选项，</p>
<p>getopt_long函数识别并返回字符'U'的ASCii码 85</p>
<p>option_find函数根据'U'的ASCii码 找到对应的pgut_option的结构体对象</p>
<p><a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/0651d94a2e99b5f497c48420d54bfba980baa43aab8cc3ecaa0e40eb4c48f7c3/68747470733a2f2f6f73732d656d637370726f642d7075626c69632e6d6f64622e70726f2f696d6167652f656469746f722f32303234303230352d38646161656332372d613233392d346436352d623532662d3761356330346266333834392e706e67"><img src="https://camo.githubusercontent.com/0651d94a2e99b5f497c48420d54bfba980baa43aab8cc3ecaa0e40eb4c48f7c3/68747470733a2f2f6f73732d656d637370726f642d7075626c69632e6d6f64622e70726f2f696d6167652f656469746f722f32303234303230352d38646161656332372d613233392d346436352d623532662d3761356330346266333834392e706e67" alt="" data-canonical-src="https://oss-emcsprod-public.modb.pro/image/editor/20240205-8daaec27-a239-4d65-b52f-7a5c04bf3849.png" style="max-width: 100%;"></a></p>
<p>pgut_setopt函数再将对应的var的值 也就是对应的全局变量<strong>username</strong>的值 修改成传入的数据"halo"，其他以此类推</p>
<p><a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/fa3689bc868b5299064037ca3bd6f34df7b7822b4de046233b641c3c1251831f/68747470733a2f2f6f73732d656d637370726f642d7075626c69632e6d6f64622e70726f2f696d6167652f656469746f722f32303234303230352d64316531346262622d356364352d346266612d623462362d3866333535356531313938652e706e67"><img src="https://camo.githubusercontent.com/fa3689bc868b5299064037ca3bd6f34df7b7822b4de046233b641c3c1251831f/68747470733a2f2f6f73732d656d637370726f642d7075626c69632e6d6f64622e70726f2f696d6167652f656469746f722f32303234303230352d64316531346262622d356364352d346266612d623462362d3866333535356531313938652e706e67" alt="" data-canonical-src="https://oss-emcsprod-public.modb.pro/image/editor/20240205-d1e14bbb-5cd5-4bfa-b4b6-8f3555e1198e.png" style="max-width: 100%;"></a></p>
<h2>4.3、ParseControlFile</h2>
<p>解析控制文件，也就是ctl文件，如<code class="notranslate">pg_bulkload ./sample_csv.ctl -d postgres -U halo</code> 中的sample_csv.ctl文件</p>
<p>在执行ParseControlFile函数前 如果不是绝对路径 会先获取完整的绝对路径</p>
<p><a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/f843bf94e9101fe07c3cd73520c0c62e6368cf243ab856ba6dbf889364509b64/68747470733a2f2f6f73732d656d637370726f642d7075626c69632e6d6f64622e70726f2f696d6167652f656469746f722f32303234303230352d61326639663938302d353230652d343366322d386235622d6239336639646537396534662e706e67"><img src="https://camo.githubusercontent.com/f843bf94e9101fe07c3cd73520c0c62e6368cf243ab856ba6dbf889364509b64/68747470733a2f2f6f73732d656d637370726f642d7075626c69632e6d6f64622e70726f2f696d6167652f656469746f722f32303234303230352d61326639663938302d353230652d343366322d386235622d6239336639646537396534662e706e67" alt="" data-canonical-src="https://oss-emcsprod-public.modb.pro/image/editor/20240205-a2f9f980-520e-43f2-8b5b-b93f9de79e4f.png" style="max-width: 100%;"></a></p>
<p>接着回到ParseControlFile函数 输入参数即为之前获取到的绝对路径</p>
<pre class="notranslate"><code class="notranslate">static List * ParseControlFile(const char *path)
{
       /* ...省略部分代码... */
	file = pgut_fopen(path, "rt");
	for (lineno = 1; fgets(buf, LINEBUF, file); lineno++)
	{
		/* ...省略部分代码... */
		for (i = 0; i &lt; NUM_PATH_OPTIONS; i++)
		{
			pgut_option *opt = &amp;options[i];
			if (pgut_keyeq(keyword, opt-&gt;lname))
			{
				pgut_setopt(opt, value, SOURCE_FILE);
				break;
			}
		}

		/* Other options */
		if (i &gt;= NUM_PATH_OPTIONS)
		{
			size_t	len;
			char   *item;
			len = strlen(keyword) + strlen(value) + 2;
			item = pgut_malloc(len);
			snprintf(item, len, "%s=%s", keyword, value);
			items = lappend(items, item);
			if (pg_strcasecmp(item, "TYPE=FUNCTION") == 0)
				type_function = true;
			if (pg_strcasecmp(item, "TYPE=BINARY") == 0 ||
				pg_strcasecmp(item, "TYPE=FIXED") == 0)
				type_binary = true;
			if (pg_strcasecmp(item, "WRITER=BINARY") == 0)
				writer_binary = true;
		}
	}

	fclose(file);
　　　　/* ...省略部分代码... */
}
</code></pre>
<p>这个函数由于和<strong>pgut_getopt</strong> 类似 所以提到<strong>LoaderRecoveryMain</strong>函数之前 他的处理逻辑其实就是通过fgets函数一行一行的获取数据 然后去解析 最后和<strong>pgut_getopt</strong>  函数一样 通过pgut_setopt去设置相关数据</p>
<p>由于<code class="notranslate">#define NUM_PATH_OPTIONS        6</code>此处他仅仅匹配处理这六个参数</p>
<p><a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/b56bf4759d60b6cbf4f68f5568b827a42d3dc33854ce94cfb2f7e4e4c3ec80f1/68747470733a2f2f6f73732d656d637370726f642d7075626c69632e6d6f64622e70726f2f696d6167652f656469746f722f32303234303230352d32323630316333662d353036302d343638392d383335302d6234663261323933383765342e706e67"><img src="https://camo.githubusercontent.com/b56bf4759d60b6cbf4f68f5568b827a42d3dc33854ce94cfb2f7e4e4c3ec80f1/68747470733a2f2f6f73732d656d637370726f642d7075626c69632e6d6f64622e70726f2f696d6167652f656469746f722f32303234303230352d32323630316333662d353036302d343638392d383335302d6234663261323933383765342e706e67" alt="" data-canonical-src="https://oss-emcsprod-public.modb.pro/image/editor/20240205-22601c3f-5060-4689-8350-b4f2a29387e4.png" style="max-width: 100%;"></a></p>
<p>当超过六个时 他会当成Other options处理，会lappend保留相关数据用于后续处理 同时判断处理类型 或者 写入方式，此处不涉及<strong>Recovery options</strong></p>
<h2>4.4、LoaderRecoveryMain</h2>
<p>此函数用于进行数据恢复，本次描述主要pg_bulkload是如何进行加载数据，感兴趣的同学可以自行查看学习此函数。</p>
<h2>4.5、LoaderLoadMain</h2>
<p>来到LoaderLoadMain函数，前面讲了相关的参数解析 一直都还没到最终处理 官方提供的pg_bulkload内部结构图也并没有得到体现 那么pg_bulkload内部结构图是否就体现在这个函数中呢？我们接着再来瞅瞅</p>
<pre class="notranslate"><code class="notranslate">static int LoaderLoadMain(List *options)
{
　　　　/* ...省略部分代码... */
	reconnect(ERROR);

　　　　/* ...省略部分代码... */
	/* form options as text[] */
	appendStringInfoString(&amp;buf, "{\"");
	foreach (cell, options)
	{
		const char *item = lfirst(cell);

		if (buf.len &gt; 2)
			appendStringInfoString(&amp;buf, "\",\"");

		/* escape " and \ */
		while (*item)
		{
			if (*item == '"' || *item == '\\')
			{
				appendStringInfoChar(&amp;buf, '\\');
				appendStringInfoChar(&amp;buf, *item);
				item++;
			}
			else if (!IS_HIGHBIT_SET(*item))
			{
				appendStringInfoChar(&amp;buf, *item);
				item++;
			}
			else
			{
				int	n = PQmblen(item, encoding);
				appendBinaryStringInfo(&amp;buf, item, n);
				item += n;
			}
		}
	}
	appendStringInfoString(&amp;buf, "\"}");

	command("BEGIN", 0, NULL);
	params[0] = buf.data;
	res = execute("SELECT * FROM pgbulkload.pg_bulkload($1)", 1, params);
	if (PQresultStatus(res) == PGRES_COPY_IN)
	{
		PQclear(res);
		res = RemoteLoad(connection, stdin, type_binary);
		if (PQresultStatus(res) != PGRES_TUPLES_OK)
			elog(ERROR, "copy failed: %s", PQerrorMessage(connection));
	}
	command("COMMIT", 0, NULL);

	errors = atoi(PQgetvalue(res, 0, 2)) +	/* parse errors */
			 atoi(PQgetvalue(res, 0, 3));	/* duplicate errors */

	elog(NOTICE, "BULK LOAD END\n"
				 "\t%s Rows skipped.\n"
				 "\t%s Rows successfully loaded.\n"
				 "\t%s Rows not loaded due to parse errors.\n"
				 "\t%s Rows not loaded due to duplicate errors.\n"
				 "\t%s Rows replaced with new rows.",
				 PQgetvalue(res, 0, 0), PQgetvalue(res, 0, 1),
				 PQgetvalue(res, 0, 2), PQgetvalue(res, 0, 3),
				 PQgetvalue(res, 0, 4));
	PQclear(res);

	disconnect();
	termStringInfo(&amp;buf);

　　　　/* ...省略部分代码... */
}
</code></pre>
<p>可以看到的是如果简单分成三段的话 其实就是通过reconnect获取了一个新的连接  然后执行了一个名为pgbulkload.pg_bulkload的数据库函数 完成之后打印出我们熟悉的身影<code class="notranslate">BULK LOAD END ...</code> 并调用disconnect关闭连接。</p>
<p>而reconnect通过先前解析存储的username、dbname等数据通过pgut_connect 最后调用libpq的接口PQconnectdb获取到了新的连接</p>
<pre class="notranslate"><code class="notranslate">void reconnect(int elevel)
{
　　　　/* ...省略部分代码... */
	if (dbname &amp;&amp; dbname[0])
		escape_param_str(&amp;buf, "dbname", dbname);
	if (host &amp;&amp; host[0])
		escape_param_str(&amp;buf, "host", host);
	if (port &amp;&amp; port[0])
		escape_param_str(&amp;buf, "port", port);
	if (username &amp;&amp; username[0])
		escape_param_str(&amp;buf, "user", username);
	if (password &amp;&amp; password[0])
		escape_param_str(&amp;buf, "password", password);

	connection = pgut_connect(buf.data, prompt_password, elevel); /* pgut_connect --》conn = PQconnectdb(info); */
　　　　/* ...省略部分代码... */
}
</code></pre>
<p>那么截至目前我们也并没有看到pg_bulkload内部结构图有所体现  而通过execute--》pgut_execute--》pgut_execute_elevel--》PQexecParams调用pgbulkload.pg_bulkload之后 就能打印最终的处理结果了 那看样子pgbulkload.pg_bulkload才是真正的pg_bulkload程序</p>
<p>pgbulkload.pg_bulkload是pg_bulkload插件中创建的一个函数，创建语句如下：</p>
<pre class="notranslate"><code class="notranslate">CREATE SCHEMA pgbulkload;

CREATE FUNCTION pgbulkload.pg_bulkload(
	IN options text[],
	OUT skip bigint,
	OUT count bigint,
	OUT parse_errors bigint,
	OUT duplicate_new bigint,
	OUT duplicate_old bigint,
	OUT system_time float8,
	OUT user_time float8,
	OUT duration float8
)
AS '$libdir/pg_bulkload', 'pg_bulkload' LANGUAGE C VOLATILE STRICT;
</code></pre>
<p>  而这一段则是在构造pgbulkload.pg_bulkload 输入参数options text[]</p>
<pre class="notranslate"><code class="notranslate">	/* form options as text[] */
	appendStringInfoString(&amp;buf, "{\"");
	foreach (cell, options)
	{
		const char *item = lfirst(cell);

		if (buf.len &gt; 2)
			appendStringInfoString(&amp;buf, "\",\"");

		/* escape " and \ */
		while (*item)
		{
			if (*item == '"' || *item == '\\')
			{
				appendStringInfoChar(&amp;buf, '\\');
				appendStringInfoChar(&amp;buf, *item);
				item++;
			}
			else if (!IS_HIGHBIT_SET(*item))
			{
				appendStringInfoChar(&amp;buf, *item);
				item++;
			}
			else
			{
				int	n = PQmblen(item, encoding);
				appendBinaryStringInfo(&amp;buf, item, n);
				item += n;
			}
		}
	}
	appendStringInfoString(&amp;buf, "\"}");
</code></pre>
<p>当执行完之后SELECT * FROM pgbulkload.pg_bulkload之后，就解析返回的out参数的数据，然后就有了类似如下的显示</p>
<pre class="notranslate"><code class="notranslate">NOTICE: BULK LOAD START
NOTICE: BULK LOAD END
        0 Rows skipped.
        100000 Rows successfully loaded.
        0 Rows not loaded due to parse errors.
        0 Rows not loaded due to duplicate errors.
        0 Rows replaced with new rows.
</code></pre>
<h1>五、简单分析pgbulkload.pg_bulkload函数</h1>
<p>接下来让我们瞅瞅pgbulkload.pg_bulkload对应的c函数的具体实现</p>
<pre class="notranslate"><code class="notranslate">Datum pg_bulkload(PG_FUNCTION_ARGS)
{
	Reader		   *rd = NULL;
	Writer		   *wt = NULL;
　　　　/* ...省略部分代码... */

	/*
	 * STEP 1: Initialization
	 */

	/* parse options and create reader and writer */
	ParseOptions(options, &amp;rd, &amp;wt, ru0.tv.tv_sec);

	/* initialize reader */
	ReaderInit(rd);

	/*
	 * We need to split PG_TRY block because gcc optimizes if-branches with
	 * longjmp codes too much. Local variables initialized in either branch
	 * cannot be handled another branch.
	 */
	PG_TRY();
	{
		/* truncate heap */
		if (wt-&gt;truncate)
			TruncateTable(wt-&gt;relid);

		/* initialize writer */
		WriterInit(wt);

		/* initialize checker */
		CheckerInit(&amp;rd-&gt;checker, wt-&gt;rel, wt-&gt;tchecker);

		/* initialize parser */
		ParserInit(rd-&gt;parser, &amp;rd-&gt;checker, rd-&gt;infile, wt-&gt;desc,
				   wt-&gt;multi_process, PG_GET_COLLATION());
	}
	PG_CATCH();
	{
		if (rd)
			ReaderClose(rd, true);
		if (wt)
			WriterClose(wt, true);
		PG_RE_THROW();
	}
	PG_END_TRY();

	/* No throwable codes here! */

	PG_TRY();
	{
		/* create logger */
		CreateLogger(rd-&gt;logfile, wt-&gt;verbose, rd-&gt;infile[0] == ':');

		start = timeval_to_cstring(ru0.tv);
		LoggerLog(INFO, "\npg_bulkload %s on %s\n\n",
				   PG_BULKLOAD_VERSION, start);

		ReaderDumpParams(rd);
		WriterDumpParams(wt);
		LoggerLog(INFO, "\n");

		BULKLOAD_PROFILE(&amp;prof_init);

		/*
		 * STEP 2: Build heap
		 */

		/* Switch into its memory context */
		Assert(wt-&gt;context);
		ctx = MemoryContextSwitchTo(wt-&gt;context);

		/* Loop for each input file record. */
		while (wt-&gt;count &lt; rd-&gt;limit)
		{
			HeapTuple	tuple;

			CHECK_FOR_INTERRUPTS();

			/* read tuple */
			BULKLOAD_PROFILE_PUSH();
			tuple = ReaderNext(rd);
			BULKLOAD_PROFILE_POP();
			BULKLOAD_PROFILE(&amp;prof_reader);
			if (tuple == NULL)
				break;

			/* write tuple */
			BULKLOAD_PROFILE_PUSH();
			WriterInsert(wt, tuple);
			wt-&gt;count += 1;
			BULKLOAD_PROFILE_POP();
			BULKLOAD_PROFILE(&amp;prof_writer);

			MemoryContextReset(wt-&gt;context);
			BULKLOAD_PROFILE(&amp;prof_reset);
		}

		MemoryContextSwitchTo(ctx);

		/*
		 * STEP 3: Finalize heap and merge indexes
		 */

		count = wt-&gt;count;
		parse_errors = rd-&gt;parse_errors;

		/*
		 * close writer first and reader second because shmem_exit callback
		 * is managed by a simple stack.
		 */
		ret = WriterClose(wt, false);
		wt = NULL;
		skip = ReaderClose(rd, false);
		rd = NULL;
	}
	PG_CATCH();
	{
		ErrorData	   *errdata;
		MemoryContext	ecxt;

		ecxt = MemoryContextSwitchTo(ccxt);
		errdata = CopyErrorData();
		LoggerLog(INFO, "%s\n", errdata-&gt;message);
		FreeErrorData(errdata);

		/* close writer first, and reader second */
		if (wt)
			WriterClose(wt, true);
		if (rd)
			ReaderClose(rd, true);

		MemoryContextSwitchTo(ecxt);
		PG_RE_THROW();
	}
	PG_END_TRY();

	count -= ret.num_dup_new;

	LoggerLog(INFO, "\n"
			  "  " int64_FMT " Rows skipped.\n"
			  "  " int64_FMT " Rows successfully loaded.\n"
			  "  " int64_FMT " Rows not loaded due to parse errors.\n"
			  "  " int64_FMT " Rows not loaded due to duplicate errors.\n"
			  "  " int64_FMT " Rows replaced with new rows.\n\n",
			  skip, count, parse_errors, ret.num_dup_new, ret.num_dup_old);

	pg_rusage_init(&amp;ru1);
	system = diffTime(ru1.ru.ru_stime, ru0.ru.ru_stime);
	user = diffTime(ru1.ru.ru_utime, ru0.ru.ru_utime);
	duration = diffTime(ru1.tv, ru0.tv);
	end = timeval_to_cstring(ru1.tv);

	memset(nulls, 0, sizeof(nulls));
	values[0] = Int64GetDatum(skip);
	values[1] = Int64GetDatum(count);
	values[2] = Int64GetDatum(parse_errors);
	values[3] = Int64GetDatum(ret.num_dup_new);
	values[4] = Int64GetDatum(ret.num_dup_old);
	values[5] = Float8GetDatumFast(system);
	values[6] = Float8GetDatumFast(user);
	values[7] = Float8GetDatumFast(duration);

	LoggerLog(INFO,
		"Run began on %s\n"
		"Run ended on %s\n\n"
		"CPU %.2fs/%.2fu sec elapsed %.2f sec\n",
		start, end, system, user, duration);

	LoggerClose();

	result = heap_form_tuple(tupdesc, values, nulls);

	BULKLOAD_PROFILE(&amp;prof_fini);
	BULKLOAD_PROFILE_POP();
	BULKLOAD_PROFILE_PRINT();

	PG_RETURN_DATUM(HeapTupleGetDatum(result));
}
</code></pre>
<p>不难看出整个函数就三个步骤，如果顺带对应着pg_bulkload内部结构图来看的话 其实就能很好的理解了</p>
<p><a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/f81fbaeef9a870e139d28e80af6c7ebdfdd2db3820a6df145df70d62fff88d32/68747470733a2f2f6f73732d656d637370726f642d7075626c69632e6d6f64622e70726f2f696d6167652f656469746f722f32303234303230342d36613531616130382d383032352d343032322d613634322d3965383163376135346238332e706e67"><img src="https://camo.githubusercontent.com/f81fbaeef9a870e139d28e80af6c7ebdfdd2db3820a6df145df70d62fff88d32/68747470733a2f2f6f73732d656d637370726f642d7075626c69632e6d6f64622e70726f2f696d6167652f656469746f722f32303234303230342d36613531616130382d383032352d343032322d613634322d3965383163376135346238332e706e67" alt="" data-canonical-src="https://oss-emcsprod-public.modb.pro/image/editor/20240204-6a51aa08-8025-4022-a642-9e81c7a54b83.png" style="max-width: 100%;"></a></p>
<p>按照结构图来看其实就分为Reader，Writer。然后Reader的Parser支持处理三种类型，如果是csv、binary这些格式，Reader的Parser还会承当一些检查转换过滤的操作，然后经过约束检查之后就可以交由Writer了，而Writer也同时支持三种处理。</p>
<p>那么如何确认Reader的Parser是处理什么类型的以及Writer应该以什么样的方式插入呢？所以整个工作就交由了Initialization</p>
<h2>5.1、Initialization</h2>
<p>对于如何确认Reader的Parser是处理什么类型的以及Writer应该以什么样的方式插入呢，我们可以看一下ParseOptions函数</p>
<pre class="notranslate"><code class="notranslate">	/* parse options and create reader and writer */
	ParseOptions(options, &amp;rd, &amp;wt, ru0.tv.tv_sec);
</code></pre>
<p>它用于解析和创建reader and writer 内部解析处理代码如下</p>
<pre class="notranslate"><code class="notranslate">	/* parse for each option */
	defs = untransformRelOptions(options);
	foreach (cell, defs)
	{
		opt = lfirst(cell);
		if (opt-&gt;arg == NULL)
			ereport(ERROR, (errcode(ERRCODE_INVALID_PARAMETER_VALUE),
					errmsg("option \"%s\" has no value", opt-&gt;defname)));

		keyword = opt-&gt;defname;
		value = strVal(opt-&gt;arg);

		if (CompareKeyword(keyword, "TYPE"))
		{
			ASSERT_ONCE(type == NULL);
			type = value;
		}
		else if (CompareKeyword(keyword, "WRITER") ||
				 CompareKeyword(keyword, "LOADER"))
		{
			ASSERT_ONCE(writer == NULL);
			writer = value;
		}
		else if (CompareKeyword(keyword, "MULTI_PROCESS"))
		{
			multi_process = ParseBoolean(value);
		}
		else
		{
			rest_defs = lappend(rest_defs, opt);
			continue;
		}
	}

	*wt = WriterCreate(writer, multi_process);
	*rd = ReaderCreate(type);
</code></pre>
<p>再来看看WriterCreate、ReaderCreate</p>
<pre class="notranslate"><code class="notranslate">Writer *
WriterCreate(char *writer, bool multi_process)
{
	const char *keys[] =
	{
		"DIRECT",
		"BUFFERED",
		"BINARY"
	};
	const CreateWriter values[] =
	{
		CreateDirectWriter,
		CreateBufferedWriter,
		CreateBinaryWriter
	};

	Writer *self;

	/* default of writer is DIRECT */
	if (writer == NULL)
		writer = "DIRECT";

	/* alias for backward compatibility. */
	if (pg_strcasecmp(writer, "PARALLEL") == 0)
	{
		multi_process = true;
		writer = "DIRECT";
	}

	self = values[choice("WRITER", writer, keys, lengthof(keys))](NULL);

	if (multi_process)
		self = CreateParallelWriter(self);

	self-&gt;multi_process = multi_process;

	return self;
}


Reader *
ReaderCreate(char *type)
{
	const char *keys[] =
	{
		"BINARY",
		"FIXED",	/* alias for backward compatibility. */
		"CSV",
		"TUPLE",
		"FUNCTION",
	};
	const ParserCreate values[] =
	{
		CreateBinaryParser,
		CreateBinaryParser,
		CreateCSVParser,
		CreateTupleParser,
		CreateFunctionParser,
	};

	Reader	   *self;

	/* default of type is CSV */
	if (type == NULL)
		type = "CSV";

	self = palloc0(sizeof(Reader));
	self-&gt;max_parse_errors = -2;
	self-&gt;limit = INT64_MAX;
	self-&gt;checker.encoding = -1;

	self-&gt;parser = values[choice("TYPE", type, keys, lengthof(keys))]();

	return self;
}
</code></pre>
<p>可以看到完完全全和结构图对应上了，再多的内容就不展开了，后续就是对应的初始化指针初始化reader（parser、checker）、writer ，如果是设置了导数据前先truncate 也是在初始化阶段执行的 ，以及创建对应的logger 用于输出日志</p>
<pre class="notranslate"><code class="notranslate">	/* initialize reader */
	ReaderInit(rd);

	/*
	 * We need to split PG_TRY block because gcc optimizes if-branches with
	 * longjmp codes too much. Local variables initialized in either branch
	 * cannot be handled another branch.
	 */
	PG_TRY();
	{
		/* truncate heap */
		if (wt-&gt;truncate)
			TruncateTable(wt-&gt;relid);

		/* initialize writer */
		WriterInit(wt);

		/* initialize checker */
		CheckerInit(&amp;rd-&gt;checker, wt-&gt;rel, wt-&gt;tchecker);

		/* initialize parser */
		ParserInit(rd-&gt;parser, &amp;rd-&gt;checker, rd-&gt;infile, wt-&gt;desc,
				   wt-&gt;multi_process, PG_GET_COLLATION());
	}
	PG_CATCH();
	{
		if (rd)
			ReaderClose(rd, true);
		if (wt)
			WriterClose(wt, true);
		PG_RE_THROW();
	}
	PG_END_TRY();
 
　　　　　　　　/* ...省略部分代码... */
		/* create logger */
		CreateLogger(rd-&gt;logfile, wt-&gt;verbose, rd-&gt;infile[0] == ':');

		start = timeval_to_cstring(ru0.tv);
		LoggerLog(INFO, "\npg_bulkload %s on %s\n\n",
				   PG_BULKLOAD_VERSION, start);

		ReaderDumpParams(rd);
		WriterDumpParams(wt);
		LoggerLog(INFO, "\n");
</code></pre>
<h2>5.2、Build heap</h2>
<p>这个部分的代码很清晰，这个阶段就是由Reader读取解析数据生成元组（关系型数据库的基础概念）检查校验完之后 然后交由Writer使用指定的方式插入指定的表中</p>
<pre class="notranslate"><code class="notranslate">		/* Loop for each input file record. */
		while (wt-&gt;count &lt; rd-&gt;limit)
		{
			HeapTuple	tuple;

			CHECK_FOR_INTERRUPTS();

			/* read tuple */
			BULKLOAD_PROFILE_PUSH();
			tuple = ReaderNext(rd);
			BULKLOAD_PROFILE_POP();
			BULKLOAD_PROFILE(&amp;prof_reader);
			if (tuple == NULL)
				break;

			/* write tuple */
			BULKLOAD_PROFILE_PUSH();
			WriterInsert(wt, tuple);
			wt-&gt;count += 1;
			BULKLOAD_PROFILE_POP();
			BULKLOAD_PROFILE(&amp;prof_writer);

			MemoryContextReset(wt-&gt;context);
			BULKLOAD_PROFILE(&amp;prof_reset);
		}
</code></pre>
<p>ReaderNext函数</p>
<p><a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/422db99593a51c501b6b6f7e2569c81ca325f462b8a5025702d59839e80dff92/68747470733a2f2f6f73732d656d637370726f642d7075626c69632e6d6f64622e70726f2f696d6167652f656469746f722f32303234303230362d31343764666263612d346564352d343834332d383535642d6430666635623966373264352e706e67"><img src="https://camo.githubusercontent.com/422db99593a51c501b6b6f7e2569c81ca325f462b8a5025702d59839e80dff92/68747470733a2f2f6f73732d656d637370726f642d7075626c69632e6d6f64622e70726f2f696d6167652f656469746f722f32303234303230362d31343764666263612d346564352d343834332d383535642d6430666635623966373264352e706e67" alt="" data-canonical-src="https://oss-emcsprod-public.modb.pro/image/editor/20240206-147dfbca-4ed5-4843-855d-d0ff5b9f72d5.png" style="max-width: 100%;"></a></p>
<h2>5.3、Finalize heap and merge indexes</h2>
<p>这一部分就是完成对writer、reader的清理、记录一些日志数据、还有一步就是生成最终的返回元组，完成函数调用，就此闭环了。</p>
<pre class="notranslate"><code class="notranslate">		/* close writer first, and reader second */
		if (wt)
			WriterClose(wt, true);
		if (rd)
			ReaderClose(rd, true)

	LoggerLog(INFO, "\n"
			  "  " int64_FMT " Rows skipped.\n"
			  "  " int64_FMT " Rows successfully loaded.\n"
			  "  " int64_FMT " Rows not loaded due to parse errors.\n"
			  "  " int64_FMT " Rows not loaded due to duplicate errors.\n"
			  "  " int64_FMT " Rows replaced with new rows.\n\n",
			  skip, count, parse_errors, ret.num_dup_new, ret.num_dup_old);

	pg_rusage_init(&amp;ru1);
	system = diffTime(ru1.ru.ru_stime, ru0.ru.ru_stime);
	user = diffTime(ru1.ru.ru_utime, ru0.ru.ru_utime);
	duration = diffTime(ru1.tv, ru0.tv);
	end = timeval_to_cstring(ru1.tv);

	memset(nulls, 0, sizeof(nulls));
	values[0] = Int64GetDatum(skip);
	values[1] = Int64GetDatum(count);
	values[2] = Int64GetDatum(parse_errors);
	values[3] = Int64GetDatum(ret.num_dup_new);
	values[4] = Int64GetDatum(ret.num_dup_old);
	values[5] = Float8GetDatumFast(system);
	values[6] = Float8GetDatumFast(user);
	values[7] = Float8GetDatumFast(duration);

	LoggerLog(INFO,
		"Run began on %s\n"
		"Run ended on %s\n\n"
		"CPU %.2fs/%.2fu sec elapsed %.2f sec\n",
		start, end, system, user, duration);

	LoggerClose();

	result = heap_form_tuple(tupdesc, values, nulls);

	BULKLOAD_PROFILE(&amp;prof_fini);
	BULKLOAD_PROFILE_POP();
	BULKLOAD_PROFILE_PRINT();

	PG_RETURN_DATUM(HeapTupleGetDatum(result));
</code></pre>
<p>六、总结</p>
<p>=======</p>
<p>来个简单的总结 只是梳理了一下 pg_bulkload大概的加载数据的过程 具体细节方面 各位可以自行调试。</p>
<p>对于pg_bulkload程序而言，</p>
<p>主要就是依据解析到的信息创建数据库连接，</p>
<p>执行<code class="notranslate">SELECT * FROM pgbulkload.pg_bulkload($1)</code> </p>
<p>解析返回数据 关闭连接</p>
<p>其实主要就是调用pgbulkload.pg_bulkload数据库函数，和给出的pg_bulkload内部结构图没有什么太大的关系，</p>
<p>或者是说pgbulkload.pg_bulkload对应的c函数才是真正的意义上的"pg_bulkload"程序。</p>
<p>此处给出pg_bulkload程序的一个大概的执行流程图</p>
<p><a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/ed15104e8eae43aa04cd92468983e0b2041e5005b31c0b7f5780c784a27045df/68747470733a2f2f6f73732d656d637370726f642d7075626c69632e6d6f64622e70726f2f696d6167652f656469746f722f32303234303230362d66623962613334642d376561382d343136302d386262392d6432393535636466623233312e706e67"><img src="https://camo.githubusercontent.com/ed15104e8eae43aa04cd92468983e0b2041e5005b31c0b7f5780c784a27045df/68747470733a2f2f6f73732d656d637370726f642d7075626c69632e6d6f64622e70726f2f696d6167652f656469746f722f32303234303230362d66623962613334642d376561382d343136302d386262392d6432393535636466623233312e706e67" alt="" data-canonical-src="https://oss-emcsprod-public.modb.pro/image/editor/20240206-fb9ba34d-7ea8-4160-8bb9-d2955cdfb231.png" style="max-width: 100%;"></a></p>
<p>此处给出pgbulkload.pg_bulkload数据库内核c函数的一个大概的执行流程图</p>
<p><a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/f40870e585fe58ce73e3ecb0ca35af64c4da28a58a83c2df2844f2ada51b21c0/68747470733a2f2f6f73732d656d637370726f642d7075626c69632e6d6f64622e70726f2f696d6167652f656469746f722f32303234303230362d38303636646664632d373433622d343363622d383932362d3236333462306530633064392e706e67"><img src="https://camo.githubusercontent.com/f40870e585fe58ce73e3ecb0ca35af64c4da28a58a83c2df2844f2ada51b21c0/68747470733a2f2f6f73732d656d637370726f642d7075626c69632e6d6f64622e70726f2f696d6167652f656469746f722f32303234303230362d38303636646664632d373433622d343363622d383932362d3236333462306530633064392e706e67" alt="" data-canonical-src="https://oss-emcsprod-public.modb.pro/image/editor/20240206-8066dfdc-743b-43cb-8926-2634b0e0c0d9.png" style="max-width: 100%;"></a></p>
<h1>七、声明</h1>
<p>由于篇幅的原因诸多细节未完全展开（又是冗长的一篇...  这个篇幅还真是有点不好控制），若文中存在错误或不当之处，敬请指出，以便我进行修正和完善。希望这篇文章能够帮助到你。</p>
<p>文章转载请联系，谢谢合作。</p></div>
<div style="font-size:small;margin-top:8px;float:right;">❤️ 转载文章请注明出处，谢谢！❤️</div>

<button class="btn btn-block" type="button" onclick="openComments()" id="cmButton">评论</button>
<div class="comments" id="comments"></div>

</div>
    <div id="footer"><div id="footer1">Copyright © <span id="copyrightYear"></span> <a href="https://Z-Xiao-M.github.io/github.io">包里装着个卡比兽</a></div>
<div id="footer2">
    <span id="runday"></span><span>Powered by <a href="https://meekdai.com/Gmeek.html" target="_blank">Gmeek</a></span>
</div>

<script>
var now=new Date();
document.getElementById("copyrightYear").innerHTML=now.getFullYear();

if("08/31/2025"!=""){
    var startSite=new Date("08/31/2025");
    var diff=now.getTime()-startSite.getTime();
    var diffDay=Math.floor(diff/(1000*60*60*24));
    document.getElementById("runday").innerHTML="网站运行"+diffDay+"天"+" • ";
}
</script></div>
</body>
<script>
var IconList={'sun': 'M8 10.5a2.5 2.5 0 100-5 2.5 2.5 0 000 5zM8 12a4 4 0 100-8 4 4 0 000 8zM8 0a.75.75 0 01.75.75v1.5a.75.75 0 01-1.5 0V.75A.75.75 0 018 0zm0 13a.75.75 0 01.75.75v1.5a.75.75 0 01-1.5 0v-1.5A.75.75 0 018 13zM2.343 2.343a.75.75 0 011.061 0l1.06 1.061a.75.75 0 01-1.06 1.06l-1.06-1.06a.75.75 0 010-1.06zm9.193 9.193a.75.75 0 011.06 0l1.061 1.06a.75.75 0 01-1.06 1.061l-1.061-1.06a.75.75 0 010-1.061zM16 8a.75.75 0 01-.75.75h-1.5a.75.75 0 010-1.5h1.5A.75.75 0 0116 8zM3 8a.75.75 0 01-.75.75H.75a.75.75 0 010-1.5h1.5A.75.75 0 013 8zm10.657-5.657a.75.75 0 010 1.061l-1.061 1.06a.75.75 0 11-1.06-1.06l1.06-1.06a.75.75 0 011.06 0zm-9.193 9.193a.75.75 0 010 1.06l-1.06 1.061a.75.75 0 11-1.061-1.06l1.06-1.061a.75.75 0 011.061 0z', 'moon': 'M9.598 1.591a.75.75 0 01.785-.175 7 7 0 11-8.967 8.967.75.75 0 01.961-.96 5.5 5.5 0 007.046-7.046.75.75 0 01.175-.786zm1.616 1.945a7 7 0 01-7.678 7.678 5.5 5.5 0 107.678-7.678z', 'sync': 'M1.705 8.005a.75.75 0 0 1 .834.656 5.5 5.5 0 0 0 9.592 2.97l-1.204-1.204a.25.25 0 0 1 .177-.427h3.646a.25.25 0 0 1 .25.25v3.646a.25.25 0 0 1-.427.177l-1.38-1.38A7.002 7.002 0 0 1 1.05 8.84a.75.75 0 0 1 .656-.834ZM8 2.5a5.487 5.487 0 0 0-4.131 1.869l1.204 1.204A.25.25 0 0 1 4.896 6H1.25A.25.25 0 0 1 1 5.75V2.104a.25.25 0 0 1 .427-.177l1.38 1.38A7.002 7.002 0 0 1 14.95 7.16a.75.75 0 0 1-1.49.178A5.5 5.5 0 0 0 8 2.5Z', 'home': 'M6.906.664a1.749 1.749 0 0 1 2.187 0l5.25 4.2c.415.332.657.835.657 1.367v7.019A1.75 1.75 0 0 1 13.25 15h-3.5a.75.75 0 0 1-.75-.75V9H7v5.25a.75.75 0 0 1-.75.75h-3.5A1.75 1.75 0 0 1 1 13.25V6.23c0-.531.242-1.034.657-1.366l5.25-4.2Zm1.25 1.171a.25.25 0 0 0-.312 0l-5.25 4.2a.25.25 0 0 0-.094.196v7.019c0 .138.112.25.25.25H5.5V8.25a.75.75 0 0 1 .75-.75h3.5a.75.75 0 0 1 .75.75v5.25h2.75a.25.25 0 0 0 .25-.25V6.23a.25.25 0 0 0-.094-.195Z', 'github': 'M8 0c4.42 0 8 3.58 8 8a8.013 8.013 0 0 1-5.45 7.59c-.4.08-.55-.17-.55-.38 0-.27.01-1.13.01-2.2 0-.75-.25-1.23-.54-1.48 1.78-.2 3.65-.88 3.65-3.95 0-.88-.31-1.59-.82-2.15.08-.2.36-1.02-.08-2.12 0 0-.67-.22-2.2.82-.64-.18-1.32-.27-2-.27-.68 0-1.36.09-2 .27-1.53-1.03-2.2-.82-2.2-.82-.44 1.1-.16 1.92-.08 2.12-.51.56-.82 1.28-.82 2.15 0 3.06 1.86 3.75 3.64 3.95-.23.2-.44.55-.51 1.07-.46.21-1.61.55-2.33-.66-.15-.24-.6-.83-1.23-.82-.67.01-.27.38.01.53.34.19.73.9.82 1.13.16.45.68 1.31 2.69.94 0 .67.01 1.3.01 1.49 0 .21-.15.45-.55.38A7.995 7.995 0 0 1 0 8c0-4.42 3.58-8 8-8Z', 'copy': 'M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 0 1 0 1.5h-1.5a.25.25 0 0 0-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 0 0 .25-.25v-1.5a.75.75 0 0 1 1.5 0v1.5A1.75 1.75 0 0 1 9.25 16h-7.5A1.75 1.75 0 0 1 0 14.25Z M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0 1 14.25 11h-7.5A1.75 1.75 0 0 1 5 9.25Zm1.75-.25a.25.25 0 0 0-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 0 0 .25-.25v-7.5a.25.25 0 0 0-.25-.25Z', 'check': 'M13.78 4.22a.75.75 0 0 1 0 1.06l-7.25 7.25a.75.75 0 0 1-1.06 0L2.22 9.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018L6 10.94l6.72-6.72a.75.75 0 0 1 1.06 0Z'};
var utterancesLoad=0;

console.log("\n %c Gmeek last https://github.com/Meekdai/Gmeek \n","padding:5px 0;background:#02d81d;color:#fff");
</script>

<script>
document.getElementById("pathHome").setAttribute("d",IconList["home"]);
document.getElementById("pathIssue").setAttribute("d",IconList["github"]);



function openComments(){
    cm=document.getElementById("comments");
    cmButton=document.getElementById("cmButton");
    cmButton.innerHTML="loading";
    span=document.createElement("span");
    span.setAttribute("class","AnimatedEllipsis");
    cmButton.appendChild(span);

    script=document.createElement("script");
    script.setAttribute("src","https://utteranc.es/client.js");
    script.setAttribute("repo","Z-Xiao-M/github.io");
    script.setAttribute("issue-term","title");
    
    script.setAttribute("theme","dark-blue");
    
    script.setAttribute("crossorigin","anonymous");
    script.setAttribute("async","");
    cm.appendChild(script);

    int=self.setInterval("iFrameLoading()",200);
}

function iFrameLoading(){
    var utterances=document.getElementsByClassName('utterances');
    if(utterances.length==1){
        if(utterances[0].style.height!=""){
            utterancesLoad=1;
            int=window.clearInterval(int);
            document.getElementById("cmButton").style.display="none";
            console.log("utterances Load OK");
        }
    }
}

document.addEventListener('DOMContentLoaded', () => {
    const createClipboardHTML = (codeContent, additionalClasses = '') => `
        <pre class="notranslate"><code class="notranslate">${codeContent}</code></pre>
        <div class="clipboard-container position-absolute right-0 top-0 ${additionalClasses}">
            <clipboard-copy class="ClipboardButton btn m-2 p-0" role="button" style="display: inherit;">
                <svg height="16" width="16" class="octicon octicon-copy m-2"><path d="${IconList["copy"]}"></path></svg>
                <svg height="16" width="16" class="octicon octicon-check color-fg-success m-2 d-none"><path d="${IconList["check"]}"></path></svg>
            </clipboard-copy>
            <div class="copy-feedback">Copied!</div>
        </div>
    `;

    const handleCodeElements = (selector = '') => {
        document.querySelectorAll(selector).forEach(codeElement => {
            const codeContent = codeElement.innerHTML;
            const newStructure = document.createElement('div');
            newStructure.className = 'snippet-clipboard-content position-relative overflow-auto';
            newStructure.innerHTML = createClipboardHTML(codeContent);

            const parentElement = codeElement.parentElement;
            if (selector.includes('highlight')) {
                parentElement.insertBefore(newStructure, codeElement.nextSibling);
                parentElement.removeChild(codeElement);
            } else {
                parentElement.parentElement.replaceChild(newStructure, parentElement);
            }
        });
    };

    handleCodeElements('pre.notranslate > code.notranslate');
    handleCodeElements('div.highlight > pre.notranslate');

    let currentFeedback = null;
    document.querySelectorAll('clipboard-copy').forEach(copyButton => {
        copyButton.addEventListener('click', () => {
            const codeContent = copyButton.closest('.snippet-clipboard-content').innerText;
            const tempTextArea = document.createElement('textarea');
            tempTextArea.value = codeContent;
            document.body.appendChild(tempTextArea);
            tempTextArea.select();
            document.execCommand('copy');
            document.body.removeChild(tempTextArea);

            const copyIcon = copyButton.querySelector('.octicon-copy');
            const checkIcon = copyButton.querySelector('.octicon-check');
            const copyFeedback = copyButton.nextElementSibling;

            if (currentFeedback && currentFeedback !== copyFeedback) {currentFeedback.style.display = 'none';}
            currentFeedback = copyFeedback;

            copyIcon.classList.add('d-none');
            checkIcon.classList.remove('d-none');
            copyFeedback.style.display = 'block';
            copyButton.style.borderColor = 'var(--color-success-fg)';

            setTimeout(() => {
                copyIcon.classList.remove('d-none');
                checkIcon.classList.add('d-none');
                copyFeedback.style.display = 'none';
                copyButton.style.borderColor = '';
            }, 2000);
        });
    });
});

</script>


</html>
