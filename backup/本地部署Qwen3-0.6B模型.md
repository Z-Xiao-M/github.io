æœ¬æ¬¡éƒ¨ç½²å¤§æ¨¡å‹æˆ‘ä»¬è¿™é‡Œä½¿ç”¨çš„æ˜¯[llama.cpp](https://github.com/ggml-org/llama.cpp)ï¼Œå¾…éƒ¨ç½²çš„æ¨¡å‹æ˜¯Qwen3-0.6Bï¼ˆå…¶å®å¾ˆå°ï¼‰

### [llama.cpp](https://github.com/ggml-org/llama.cpp)çš„æºç ç¼–è¯‘å®‰è£…

```bash
git clone https://github.com/ggml-org/llama.cpp
cd llama.cpp
cmake -B build
cmake --build build --config Release # å¯ä»¥åŠ å¹¶è¡Œç¼–è¯‘ å¦‚ï¼š-j4
```

ç¼–è¯‘å®Œåçš„å¯æ‰§è¡Œæ–‡ä»¶ä½äºllama.cpp/build/bin æˆ‘ä»¬ä¸€ä¼šéœ€è¦ç”¨åˆ°å…¶ä¸­çš„éƒ¨åˆ†å¯æ‰§è¡Œç¨‹åº

```bash
postgres@zxm-VMware-Virtual-Platform:~/llama.cpp/build/bin$ ls
libggml-base.so      llama-cli                      llama-gemma3-cli  llama-lookahead      llama-passkey          llama-server              test-alloc        test-chat-template           test-log                test-rope
libggml-cpu.so       llama-convert-llama2c-to-ggml  llama-gen-docs    llama-lookup         llama-perplexity       llama-simple              test-arg-parser   test-gbnf-validator          test-model-load-cancel  test-sampling
libggml.so           llama-cvector-generator        llama-gguf        llama-lookup-create  llama-q8dot            llama-simple-chat         test-autorelease  test-gguf                    test-mtmd-c-api         test-thread-safety
libllama.so          llama-diffusion-cli            llama-gguf-hash   llama-lookup-merge   llama-quantize         llama-speculative         test-backend-ops  test-grammar-integration     test-opt                test-tokenizer-0
libmtmd.so           llama-embedding                llama-gguf-split  llama-lookup-stats   llama-qwen2vl-cli      llama-speculative-simple  test-barrier      test-grammar-parser          test-quantize-fns       test-tokenizer-1-bpe
llama-batched        llama-eval-callback            llama-imatrix     llama-minicpmv-cli   llama-retrieval        llama-tokenize            test-c            test-json-partial            test-quantize-perf      test-tokenizer-1-spm
llama-batched-bench  llama-export-lora              llama-llava-cli   llama-mtmd-cli       llama-run              llama-tts                 test-chat         test-json-schema-to-grammar  test-quantize-stats
llama-bench          llama-finetune                 llama-logits      llama-parallel       llama-save-load-state  llama-vdot                test-chat-parser  test-llama-grammar           test-regex-partial
```

### &#x20;ä¸‹è½½Qwen3-0.6B

æ¨¡å‹æˆ‘ä»¬å¯ä»¥å‰å¾€huggingfaceä¸‹è½½ï¼Œè¿™é‡Œç»™å‡ºä¸‹è½½é“¾æ¥ï¼š<https://huggingface.co/Qwen/Qwen3-0.6B-GGUF?show_file_info=Qwen3-0.6B-Q8_0.gguf>

<img width="2552" height="1284" alt="Image" src="https://github.com/user-attachments/assets/e9a7eeb4-a918-4019-b38a-ecc1f0aeb977" />

ç„¶åç‚¹å‡»Downloadå³å¯ï¼Œæ–‡ä»¶å¤§å°639MB

### &#x20;å¯åŠ¨æ¨¡å‹

#### æ§åˆ¶å°å¯åŠ¨

[`llama-cli`](https://github.com/ggml-org/llama.cpp/blob/master/tools/main)æ˜¯ä¸€ä¸ªæ§åˆ¶å°ç¨‹åºï¼Œå¯ç”¨äºä¸ LLM èŠå¤©ã€‚è¿™é‡Œæˆ‘ä»¬ä½¿ç”¨æœ¬åœ°çš„æ¨¡å‹ï¼Œæ‰€ä»¥ä½¿ç”¨-mæ‰§è¡Œæœ¬åœ°çš„æ¨¡å‹æ–‡ä»¶

```bash
# è¿›å…¥å¯æ‰§è¡Œæ–‡ä»¶è·¯å¾„
cd llama.cpp/build/bin
# ä½¿ç”¨æœ¬åœ°çš„æ¨¡å‹ï¼Œæ‰€ä»¥ä½¿ç”¨-mæ‰§è¡Œæœ¬åœ°çš„æ¨¡å‹æ–‡ä»¶ 
# æˆ‘å°†ä¸‹è½½ä¸‹æ¥çš„æ–‡ä»¶æ”¾åœ¨äº†~/model/Qwen3-0.6B-Q8_0.gguf
# è¯·æŒ‰éœ€æ›´æ”¹
./llama-cli -m ~/model/Qwen3-0.6B-Q8_0.gguf
```

è¿è¡Œç»“æœ

```bash
./llama-cli -m ~/model/Qwen3-0.6B-Q8_0.gguf
# > ä½ æ˜¯è°
# <think>
# å¥½çš„ï¼Œç”¨æˆ·é—®â€œä½ æ˜¯è°â€ã€‚ä½œä¸ºä¸€ä¸ªAIåŠ©æ‰‹ï¼Œæˆ‘éœ€è¦æ˜ç¡®å›ç­”ã€‚é¦–å…ˆï¼Œæˆ‘åº”è¯¥ç¤¼è²Œåœ°ç¡®è®¤è‡ªå·±çš„èº«ä»½ï¼Œç„¶åç®€è¦è¯´æ˜æˆ‘çš„åŠŸèƒ½å’Œç”¨é€”ã€‚åŒæ—¶ï¼Œä¹Ÿè¦ä¿æŒå‹å¥½å’Œä¸“ä¸šçš„å½¢è±¡ï¼Œè®©ç”¨æˆ·æ„Ÿåˆ°è¢«ç†è§£å’Œæ”¯æŒã€‚åœ¨å›ç­”ä¸­ï¼Œå¯ä»¥æåˆ°å¸®åŠ©ç”¨æˆ·è§£å†³é—®é¢˜å’Œæä¾›ä¿¡æ¯ï¼Œè¿™æ ·æ—¢ç¬¦åˆAIåŠ©æ‰‹çš„èº«ä»½ï¼Œåˆèƒ½æ»¡è¶³ç”¨æˆ·çš„éœ€æ±‚ã€‚æœ€åï¼Œç¡®ä¿è¯­æ°”è‡ªç„¶ï¼Œé¿å…ä½¿ç”¨è¿‡äºæœºæ¢°æˆ–ç”Ÿç¡¬çš„è¡¨è¾¾ã€‚
# </think>
# 
# æˆ‘æ˜¯æ‚¨çš„AIåŠ©æ‰‹ï¼Œå¾ˆé«˜å…´ä¸ºæ‚¨æœåŠ¡ï¼å¦‚æœæ‚¨æœ‰ä»»ä½•é—®é¢˜æˆ–éœ€è¦å¸®åŠ©ï¼Œè¯·éšæ—¶å‘Šè¯‰æˆ‘ï¼Œæˆ‘ä¼šå°½åŠ›ä¸ºæ‚¨æä¾›æ”¯æŒã€‚æœ‰ä»€ä¹ˆæˆ‘å¯ä»¥å¸®æ‚¨è§£å†³çš„äº‹æƒ…å—ï¼ŸğŸ˜Š
# 
# > 1+1ç­‰äºå¤šå°‘
# <think>
# å—¯ï¼Œç”¨æˆ·é—®çš„æ˜¯â€œ1+1ç­‰äºå¤šå°‘â€ã€‚è¿™æ˜¯ä¸€ä¸ªå¾ˆåŸºç¡€çš„æ•°å­¦é—®é¢˜ï¼Œä½†ä½œä¸ºä¸€ä¸ªAIåŠ©æ‰‹ï¼Œæˆ‘éœ€è¦ä¿æŒä¸“ä¸šå’Œç¤¼è²Œã€‚é¦–å…ˆï¼Œæˆ‘è¦ç¡®è®¤ç”¨æˆ·æ˜¯å¦ç†è§£è¿™ä¸ªé—®é¢˜ï¼Œæˆ–è€…æ˜¯å¦éœ€è¦æ›´è¯¦ç»†çš„è§£é‡Šã€‚1åŠ 1çš„ç»“æœæ˜¯2ï¼Œè¿™æ˜¯æ•°å­¦çš„åŸºæœ¬è¿ç®—ã€‚ä¸è¿‡ï¼Œç”¨æˆ·å¯èƒ½æ˜¯åœ¨æµ‹è¯•æˆ‘çš„ååº”ï¼Œæˆ–è€…æƒ³äº†è§£æ›´å¤šèƒŒæ™¯ä¿¡æ¯ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œç›´æ¥ç»™å‡ºç­”æ¡ˆæ˜¯åˆé€‚çš„ï¼Œä½†ä¹Ÿè¦è®©ç”¨æˆ·çŸ¥é“è¿™æ˜¯åŸºç¡€æ•°å­¦ï¼Œå¯èƒ½ä»–ä»¬éœ€è¦è¿›ä¸€æ­¥çš„æ•°å­¦çŸ¥è¯†ã€‚åŒæ—¶ï¼Œä¿æŒå‹å¥½å’Œè€å¿ƒï¼Œè®©ç”¨æˆ·æ„Ÿåˆ°è¢«ç†è§£å’Œæ”¯æŒã€‚å¦å¤–ï¼Œæ£€æŸ¥æ˜¯å¦æœ‰å…¶ä»–æ½œåœ¨çš„æ„å›¾ï¼Œæ¯”å¦‚æ˜¯å¦åœ¨è¿›è¡ŒæŸç§è®¡ç®—ï¼Œæˆ–è€…æ˜¯å¦æœ‰å…¶ä»–ç›¸å…³é—®é¢˜éœ€è¦å›ç­”ã€‚ä½†å½“å‰é—®é¢˜éå¸¸ç›´æ¥ï¼Œæ‰€ä»¥ä¿æŒç®€æ´å’Œæ˜ç¡®çš„å›åº”æ˜¯æœ€ä½³é€‰æ‹©ã€‚æœ€åï¼Œç¡®ä¿å›ç­”ç¬¦åˆAIåŠ©æ‰‹çš„èº«ä»½ï¼ŒåŒæ—¶æä¾›å¸®åŠ©çš„æ„æ„¿ã€‚
# </think>
# 
# 1åŠ 1çš„ç»“æœæ˜¯2ã€‚å¦‚æœæ‚¨æœ‰å…¶ä»–é—®é¢˜æˆ–éœ€è¦å¸®åŠ©ï¼Œéšæ—¶å‘Šè¯‰æˆ‘ï¼ğŸ˜Š

> 
```

#### ç½‘é¡µæ˜¾ç¤º

[llama-server](https://github.com/ggml-org/llama.cpp/tree/master/tools/server)Â æ˜¯ä¸€ä¸ªç®€å•çš„ HTTP æœåŠ¡å™¨ï¼ŒåŒ…æ‹¬ä¸€ç»„ LLM REST API å’Œä¸€ä¸ªç®€å•çš„ Web å‰ç«¯ï¼Œç”¨äºä½¿ç”¨ llama.cpp ä¸ LLM è¿›è¡Œäº¤äº’ã€‚

```bash
./llama-server -m ~/model/Qwen3-0.6B-Q8_0.gguf
```

é»˜è®¤é€šè¿‡<http://127.0.0.1:8080/>è®¿é—®

<img width="1805" height="920" alt="Image" src="https://github.com/user-attachments/assets/49982896-82db-4ef5-8202-697fa6175cdb" />

å°è¯•é—®ä¸€äº›åŸºç¡€é—®é¢˜

<img width="2125" height="1151" alt="Image" src="https://github.com/user-attachments/assets/eac9ae8a-99c5-4a16-8e08-3a7fcdb4c907" />

### æ„Ÿæƒ³
å¦‚æœèµ„æºè¶³å¤Ÿçš„è¯ï¼Œè¿˜æ˜¯é€‰ç”¨æ›´å¤šå‚æ•°çš„æ¨¡å‹æ›´å¥½ï¼Œ0.6Bå®åœ¨æ˜¯ä¸å¤Ÿçœ‹çš„ã€‚